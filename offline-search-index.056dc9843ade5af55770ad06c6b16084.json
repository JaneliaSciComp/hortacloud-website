[{"body":"HortaCloud is a streaming 3D annotation platform for large microscopy data that runs entirely in the cloud. It is a free, open source research software tool, developed by Janelia Research Campus.\nIt combines state-of-the-art volumetric visualization, advanced features for 3D neuronal annotation, and real-time multi-user collaboration with a set of enterprise-grade backend microservices for moving and processing large amounts of data rapidly and securely. HortaCloud takes advantage of cloud-based Virtual Desktop Infrastructure (VDI) to perform all 3D rendering in cloud-leased GPUs which are data-adjacent, and only transfer a high-fidelity interactive video stream to each annotator’s local compute platform through a web browser.\nWhat is it good for?: HortaCloud is a powerful tool for 3D visualization and annotation of large-scale microscopy data. It has been used to trace axons across the entire mouse brain by Janelia’s MouseLight Team Project.\nWhat is it not good for?: HortaCloud is a very specialized tool for sparse microscopy data. It is not intended for annotation of dense data sets, such as electron microscopy (EM) imagery.\nWhat makes HortaCloud unique?: Leveraging state-of-the-art services on AWS allows HortaCloud to run entirely in the cloud, making it possible to visualize terabyte-scale 3D volumes without moving all of that data over the Internet (see diagram below).\nWhere should I go next? If you are a HortaCloud user, read through the User Manual to get familiar with the tools.\nIf you are a system administrator or developer looking to deploy an instance of HortaCloud, start with the AWS Deployment Guide.\n","categories":"","description":"What is HortaCloud?\n","excerpt":"What is HortaCloud?\n","ref":"/docs/overview/","tags":"","title":"Overview"},{"body":"The sections below describe Horta’s basic and advanced features. Generally the sections listed below should be read in the order listed.\nNote on Horta versions The Horta application exists in two versions that come from a common code base. The cloud version (HortaCloud) that is available here is a reduced version of the desktop version (Janelia Workstation). In fact, we’ll often use the word “workstation” to refer to the Horta application in either form.\nWhen there are differences between the two versions, they will be noted with “(HortaCloud)” and “(desktop)”. If the differences are more substantial, they will be presented like this:\nHortaCloud only In HortaCloud, the following control behaves differently from the desktop version. Desktop only The following features is only available in the desktop version of the Janelia Workstation. The major user-visible differences between the two versions are:\nHortaCloud does not have access to the local file system or clipboard and requires additional steps to import or export data via those routes (see AppStream Basics section for details) HortaCloud datasets typically only include low-resolution 2D data, so some 2D tools are not as useful or may not function in the absence of high-resolution data (eg, automatic path tracing) the desktop Janelia Workstation contains tools for viewing, annotating, and managing other unrelated Janelia datasets This is a work in progress!\nThe original documentation for the desktop version of Horta and the Janelia Workstation are being adapted for HortaCloud, and this website. If something doesn’t make sense for HortaCloud, it probably only applies to the desktop version and hasn’t been revised yet.\n","categories":"","description":"How to use the Horta application\n","excerpt":"How to use the Horta application\n","ref":"/docs/user_manual/","tags":"","title":"User manual"},{"body":"HortaCloud is easily deployed on Amazon Web Services (AWS) using the AWS CDK to automatically provision resources.\n","categories":"","description":"Learn how to deploy and operate your own HortaCloud instance on AWS\n","excerpt":"Learn how to deploy and operate your own HortaCloud instance on AWS\n","ref":"/docs/administration/aws/","tags":"","title":"AWS"},{"body":"The data that is currently backed up is the Mongo database and the Cognito users. The backup is enabled automatically, if and only if at the deployment time the HORTA_BACKUP_BUCKET environment variable is set. If no such environment variable is specified no data will be backed up. In addition to the backup bucket you can also specify the base prefix for the backups using HORTA_BACKUP_FOLDER, but if this is not specified the prefix will default to “/hortacloud/backups”. The location of the backups will be s3://\u003cbackup_bucket\u003e/\u003cbackup_folder_prefix\u003e/\u003ctimestamp\u003e/jacs for the database and s3://\u003cbackup_bucket\u003e/\u003cbackup_folder_prefix\u003e/\u003ctimestamp\u003e/cognito for cognito users.\nThe backup is configured as a cron job that runs daily at 3 AM local time on the EC2 host on which the backend JACS stack runs. At this time the job scheduling is not configurable, but nevertheless it is possible to change it by connecting to the EC2 instance and changing the corresponding cront entry.\n","categories":"","description":"How to backup your HortaCloud data\n","excerpt":"How to backup your HortaCloud data\n","ref":"/docs/administration/aws/backup/","tags":"","title":"Backup"},{"body":"Data Light microscopes of various kinds can now image an entire fly or mouse brain (eg, resonant scanning two photon with integrated vibrotome or Bessel light sheet). Horta is capable of displaying and annotating the resulting multi-terabyte datasets. The details of how the data should be prepared for use in Horta is covered in the Horta Reference section. In general, though, the data will have these properties:\nsize: generally limited by disk space (local or cloud) channels: two channels are supported and tested; three channels are supported but not well tested; four or more channels are possible but would require more development location: the data will be on a storage system accessible to the image server (HortaCloud) AWS S3 bucket (desktop) local or networked storage available to the workstation servers the file path to the data should be known to the user if they will be creating samples manually arrangement: the 2D and 3D images are arranged in multi-resolution octrees; details are covered in the reference section, but the user doesn’t need to know them Software \u0026 tasks Horta includes the Horta 2D viewer, which is the 2D, plane-by-plane, viewing and annotation tool, and the Horta 3D viewer, which supports viewing and annotating the data in three dimensions. The two viewers connect to common data editing and storage functions, many of which can be viewed in the Horta Control Center.\nHorta is designed for a variety of tasks:\nviewing data: panning, zooming in and out, and scrolling through planes; brightness and contrast adjustment skeletal tracing of neurons: tracer places connected points on the signal text annotation: each point can have arbitrary text added to it import/export: skeletons can be imported or exported as SWC files; text notes are imported/exported as JSON (see reference section for details) Why the name 'Horta'? “Horta” is the name of a tunneling silicon based lifeform from the Star Trek original series episode 25 “The Devil in the Dark”. Neuron traces in 3D resemble the tunnels such a creature might make in the ground. “Horta” can also be conveniently backronymed as “How Outstanding Researchers Trace Axons”. Workflows The basic tools can be used to implement a variety of workflows. For example, a user may trace a neuron entirely on their own. Or two users may trace the same neuron, export their results, and a later user may compare those results either by importing them both back in to the workstation or using other tools. If computational methods can trace neurons and export the results as SWC files, those results can be imported into the workstation for validation and/or correction and extension by later users. This flexibility supports neuron reconstruction at both small and large scales.\nJargon basic objects in Horta: sample: the data; specifically, the object in the workstation that represents a particular image dataset; it’s independent of user, and it’s all you need if you are only viewing the data workspace: the object in the workstation that collects a set of annotations (traced neurons and text annotations); it is owned by a user or group, and it contains neurons neuron: the object that holds the traced neuron skeletons; a neuron usually contains one or more neurites neurite: a single skeleton or tree; a group of annotations with parent-child relationships, all tracing back to a single root without a parent annotation: a single point that may have zero or one parent and zero or more children; annotations are sometimes called anchors tag: a word or phrase attached to a neuron; it may be used in filtering the neuron list or in controlling neuron appearance owner: a username or group that owns the neuron; if a neuron is owned by a user, only they may change it; if a neuron is owned by a group, any member of the group may take sole ownership of the neuron (and then change it) data and data formats: tiles or octree: the files holding the 2D data ktx tiles: the files holding the 3D data SWC file: a common multi-column text file format for storing neuron skeletons JSON file: a common structured text file format used to import/export text annotations tracing methods \u0026 workflows: manual: a tracer clicks along the signal in the data to create a neuron skeleton semi-automated: a computer program partially traces the signal in a dataset; the fragments are imported into the workstation; a tracer connects and/or extends fragments as needed to produce the skeleton ","categories":"","description":"High-level description of the data, the software, and the jargon\n","excerpt":"High-level description of the data, the software, and the jargon\n","ref":"/docs/user_manual/concepts/","tags":"","title":"Concepts"},{"body":"The deployment uses AWS CDK to create AWS resources on your AWS account as shown in the diagram below. All services run in a secured Virtual Private Cloud (VPC).\nInstall prerequisites You should have node v14 installed on your local machine. We recommend using nvm to install and activate this version of node.\nInstall AWS CLI\nAWS CDK requires AWS CLI to be installed and configured on the computer from which one runs the deployment procedure. Installation \u0026 configuration instructions can be found in the AWS documentation. Install AWS CDK by running\nnpm install This command will install CDK in your development environment so you can access its help as below (notice the ‘–’ separator between cdk and cdk options - this is specific to npm not to cdk so all CDK flags must be after the double hyphen separator):\nnpm run cdk -- --help Get the deployment scripts Clone the HortaCloud GitHib repository containing the deployment scripts:\ngit clone https://github.com/JaneliaSciComp/hortacloud/ cd hortacloud Install the dependencies:\nnpm run setup -- -i Configure environment The following values must be set in the .env file:\nAWS_REGION=\u003cyour aws region\u003e AWS_ACCOUNT=\u003cyour aws account\u003e HORTA_ORG=\u003capp qualifier name\u003e ADMIN_USER_EMAIL=\u003cadmin email\u003e JACS_JWT_KEY=\u003ca 32 byte jwt secret\u003e JACS_MONGO_KEY=\u003ca 32 byte mongo secret\u003e JACS_APP_PASSWD=\u003capp password\u003e RABBITMQ_PASSWD=\u003crabbitmq password\u003e JACS_API_KEY=\u003cjacs api key\u003e JADE_API_KEY=\u003cjade api key\u003e HORTA_DATA_BUCKETS=\u003cs3 buckets that hold MouseLight data\u003e The api keys and secrets have been randomly generated during the setup step, but you can generate new ones with the following command:\nopenssl rand -hex 32 We prefer this procedure because these values will be handled during the installation using the sed command and it is preferable that they not contain any characters that require escaping in a sed command.\nIf you already have data on some S3 buckets you can add them to HORTA_DATA_BUCKETS as a comma separated list. For example, if you want to use Janelia’s Open Data bucket but in addition you also have your data on a private bucket (‘janelia-mouseligh-demo’ in this example) you need to set HORTA_DATA_BUCKETS=\"janelia-mouselight-imagery,janelia-mouselight-demo\". Currently it is set to Janelia’s open data MouseLight bucket only. Every bucket specified in the ‘HORTA_DATA_BUCKETS’ list will be available in the workstation as /\u003cs3BucketName\u003e directory.\nIf you want to change the setting for HORTA_WS_INSTANCE_TYPE, keep in mind that you may have to change HORTA_WS_IMAGE_NAME For HORTA_WS_INSTANCE_TYPE set to any stream.graphics.g4dn.* instances:\nstream.graphics.g4dn.xlarge stream.graphics.g4dn.2xlarge stream.graphics.g4dn.4xlarge stream.graphics.g4dn.8xlarge stream.graphics.g4dn.12xlarge stream.graphics.g4dn.16xlarge use: HORTA_WS_IMAGE_NAME=AppStream-Graphics-G4dn-WinServer2019-07-19-2021 image.\nFor HORTA_WS_INSTANCE_TYPE set to any stream.graphics-pro.* instances:\nstream.graphics-pro.4xlarge stream.graphics-pro.8xlarge stream.graphics-pro.16xlarge use HORTA_WS_IMAGE_NAME=AppStream-Graphics-Pro-WinServer2019-10-08-2021 image\nConfigure AWS account IAM Required Roles In order to create an AppStream Image Builder, which is needed to create the Workstation Image, you need to have all roles required by AppStream. Check that by simply connecting to the AWS console and check if the Roles are available in the IAM Service - select “Services” \u003e “Security, Identity, Compliance” \u003e “IAM” then verify that the required roles are present:\nAmazonAppStreamServiceAccess ApplicationAutoScalingForAmazonAppStreamAccess AWSServiceRoleForApplicationAutoScaling_AppStreamFleet AWS Limits Most AWS services allow you to setup restrictions on the number of active instances. The default limits, especially for some AppStream resources, such as “Maximum ImageBuilders” for some graphics instances - “stream.graphics.g4dn.xlarge” may be really low (0 in some cases). Connect to AWS console “Service Quotas” service and increase the limit for in case you see a limit was exceeded error. Typically take a look at the limits setup for your account for EC2, VPC, AppStream, S3. Keep in mind that limits may be different from instance type to instance type for AppStream service, so you may have to adjust the limits based on the AppStream instance type selection.\nDeploy HortaCloud services to AWS After the setup is complete, deploy the application by running:\nnpm run deploy First time the application is deployed we also need to create user login pool and this must be explicitly specified using ‘-u’ flag [See Deploy the user login stack section below]:\nnpm run deploy -- -u There are a few steps during the deployment that require manual intervention. The deploy script will indicate when these steps should be taken with a ⚠️ warning message.\nThe full deployment of the application is done in 3, or 4 steps - if user login stack is deployed too, that run automatically one after the other, with some manual intervention for AppStream builder step (third step outlined below):\nDeploy the user login stack - this step is optional and practically is only needed first time the application is deployed. To create the user login stack you need to pass in ‘-u’ flag to the deploy command (npm run deploy -- -u) which will automatically create a Cognito user pool and the ‘admin’ user and ‘admins’ group. You also have an option to import cognito users from a backup (npm run deploy -- -u \\ -r -b janelia-mouselight-demo -f hortacloud/backups/20220511030001/cognito) but in this case you may need to skip the creation of the default admin user and group.\nDeploy the back-end stacks - this includes the AppStream builder. At the back end deployment the installation process will also create the admin user configured in ADMIN_USER_EMAIL.\nConnect to AppStream builder and install the workstation application - This is a semiautomated step that involves copying and running two PowerShell scripts onto the AppStream builder instance.\nDeploy the administration stack.\nWorkstation app installation For client installation start and connect to the AppStream builder instance then copy the following scripts from this repo to the AppStream instance:\ninstallcmd.ps1 - installs JDK and the workstation createappimage.ps1 - creates the AppStream image After you copied or created the scripts:\nLog in to the AWS console and go to https://console.aws.amazon.com/appstream2 Find your new builder in the “Images \u003e Image Builder” tab Click on the image name and open an “Administrator” window by clicking on the “Connect” button. Copy the installation scripts from your local machine to AppStream: Click on the folder icon at the top left of the window Select the Temporary Files folder Use the Upload Files icon to find the files on your machine and upload them. Open the powershell by typing “`Power shell” in the search found at the bottom left of the window. This step used to require an “Administrator Power Shell” but now it needs only a regular user power shell and it may actually fail the install if you run it in an Administrator Power Shell. Change to the directory where you uploaded the installation scripts, eg: cd 'C:\\Users\\ImagebuilderAdmin\\My Files\\Temporary Files' Run the installcmd script to install the workstation. \u003cserverName\u003e is the name of the backend EC2 instance, typically it looks like ip-\u003cip4 with dashes instead of dots\u003e.ec2.internal. Instructions for locating this are provided as output from the installer script. installcmd.ps1 \u003cserverName\u003e This will install the JDK and the workstation. The installer will run silently and it will install the workstation under the C:\\apps folder. If it prompts you for the install directory, select C:\\apps as the JaneliaWorkstation location.\nOptional - To start the workstation for testing, run: c:\\apps\\runJaneliaWorkstation.ps1 when prompted, login as the admin user you set in ADMIN_USER_EMAIL (leave the password empty)\nNavigate through the menus to make sure the workstation is working. Do not create any user accounts at this time as they will get created from the Admin web application.\nWhen testing is finished, close down the workstation.\nFinalize the creation of the AppStream image, run:\ncreateappimage.ps1 Keep in mind that once you start this step the builder instance begins the snap shotting process and it will not be usable until it completes. After this is completed the AppStream image should be available and the builder will be in a stop state. To use it again you need to start it and then you can connect.\nYou can now safely close the AppStream session and return to the AppStream console. There you will see a new image in the image registry with a status of Pending. Once the image status has changed to a status of Available you can start the fleet by going to the Fleets page on the AppStream site. Select your fleet from the list of fleets and then select ‘Start’ from the Action menu. At this point the installation script you started on your host machine, should continue to completion. Customizing the portal URL By default the application will have a very long url that is not easy to remember, something like: http://janelia-hortacloudwebapp-janeliahortacloudwebadmi-yefcny29t8n6.s3-website-us-east-1.amazonaws.com/. Follow these instructions to create a shorter domain for use with your installation.\nRegister a domain with Route53 or your domain provider. The Route53 page in the AWS console has a “Register domain” form. Alternative providers can also be used, but it requires a little more work. Purchase an SSL certificate for your domain. This can be done with AWS Certificate Manager or an external certificate provider, often it can be done with the same company that provided your domain registration. Use the “Import a certificate” button to register your certificate with AWS. Use the “Create distribution” button on the CloudFront console to attach your registered domain to the s3 bucket that hosts the admin portal. the only things that need to be changed from the defaults are “Origin domain” - this should be the domain that was originally generated for your admin portal. eg: janelia-hortacloudwebapp-janeliahortacloudwebadmi-yefcny29t8n6.s3-website-us-east-1.amazonaws.com “Viewer protocol policy” - Change this to “Redirect HTTP to HTTPS” “Custom SSL certificate” - Select the certificate that you registered with AWS Certificate Manager Finally, click the “Create distribution” button. Upgrading HortaCloud services to AWS Brute Force Approach This method requires removing (uninstalling) the existing HortaCloud stack and then reinstalling it. Because of the requirement to remove the existing installation the approach there is a relatively high risk of loosing the data, so before starting anything it is best to check that the latest backup or some backup is available. Upgrading the application typically only requires a backend and an application frontend upgrade - without any need to migrate the users so you only need to check if a backup for the JACS Mongo database exists typically at s3://\u003cHORTA_BACKUP_BUCKET value\u003e/\u003cHORTA_BACKUP_FOLDER value\u003e/\u003ctimestamp\u003e/jacs\nTo uninstall current HortaCloud instance run:\nnpm run destroy This command will uninstall the frontend and the backend AWS Cloudformation stacks, i.e., Admin, Appstream and JACS stacks, but it will not uninstall Cognito stack, so no user account will be removed.\nThe next step is to upgrade the local git repo using\ngit pull followed by redeploying the application.\nIn order to restore the database from an existing backup make sure the following properties are set:\nHORTA_RESTORE_BUCKET=\u003cbackup bucket name\u003e HORTA_RESTORE_FOLDER=\"/hortacloud/backups/latest\" HORTA_RESTORE_BUCKET is the name of the backup bucket and HORTA_RESTORE_FOLDER must reference the parent prefix containing the ‘jacs’ folder - the location of the actual mongo backup. Typically the backup job creates a “softlink” - “/hortacloud/backups/latest” so if you simply set the restore folder to that it should pick up the latest backup. If the backup was a manual backup or you need to restore to a previous date set the restore folder to that folder. For example setting HORTA_RESTORE_FOLDER=/hortacloud/backups/20220609030001 will restore the database to the content saved on “Jun 9, 2022”.\nAfter setting these properties you can proceed with the actual deploy procedure which will only install the backend and the frontend stack (skipping any Cognito installation):\nnpm run deploy If somehow you need to recreate the user login accounts because you inadvertently removed the Cognito stack as well (using ‘-u’ flag) you can restore all the accounts from a previous backup using the following command:\nnpm run deploy -- -u -r -b \u003cbackup bucket\u003e -f hortacloud/backups/manual-backup/cognito The folder parameter must point to the actual cognito prefix, where ‘users.json’ and ‘groups.json’ are located\nIncremental approach Incremental approach is more manual but it does not require any data restore. It basically removes only the frontend stacks, i.e. Appstream and admin app and it requires a manual update of the backend stack and of the workstation. The steps for the incremental approach are the following:\nRemove only the frontend stacks: npm run destroy -- -b From the AWS console connect to the EC2 instance (\u003cORG\u003e-hc-jacs-node-\u003cSTAGE\u003e) running the JACS stack. Once connected run the following commands cd /opt/jacs/deploy ./manage.sh compose down sudo git pull origin stable ./manage.sh compose up -d Start AppStream builder (\u003cORG\u003e-hc-image-builder-\u003cSTAGE\u003e) Connect as Administrator Check that ‘reinstallwsonly.ps1’ script is available, in the Admin’s home directory. If not copy it from the application repo or just create it like the other install scripts, (‘installcmd.ps1’ and ‘createappimage.ps1’) were created on the initial deployment. Run the reinstallwssonly.ps1 script: .\\reinstallwssonly.ps1 \u003cIP of host running JACS stack\u003e The IP of the host running JACS is the same used for initial run of ‘installcmd.ps1’ and it can be found from the AWS console. Try out the workstation application to make sure it works C:\\apps\\runJaneliaWorkstation.ps1 Start the script for creating the AppStream image .\\createappimage.ps1 Reinstall the frontend stacks npm run deploy If no changes were made to the code CDK is smart enough to only update the missing stacks, leaving JACS stack as is since the stack already exists Uninstalling HortaCloud services to AWS To completely uninstall the application run:\nnpm run destroy -- -u The command will uninstall all stacks including the user logins (Cognito) stack.\nNote in the previous system upgrade section that an upgrade typically does not require removing and recreating the user pool stack.\nTroubleshooting Troubleshooting client app installation If the client app installation fails for any reason, before you attempt the install again you must remove everything that was installed by the install script. Uninstall all applications installed with scoop and remove the ‘C:\\apps’ folder. To do that run:\nscoop uninstall scoop del c:\\apps When prompted whether you really want to uninstall everything, select “yes” or “all”.\n","categories":"","description":"How to deploy HortaCloud to your own AWS account\n","excerpt":"How to deploy HortaCloud to your own AWS account\n","ref":"/docs/administration/aws/deployment/","tags":"","title":"Deployment"},{"body":"","categories":"","description":"Getting started with HortaCloud development\n","excerpt":"Getting started with HortaCloud development\n","ref":"/docs/development/gettingstarted/","tags":"","title":"Getting started"},{"body":"The recommended way to deploy HortaCloud is to use Amazon Web Services (AWS).\n","categories":"","description":"How to deploy and administer the HortaCloud system\n","excerpt":"How to deploy and administer the HortaCloud system\n","ref":"/docs/administration/","tags":"","title":"Administration guide"},{"body":"The AppStream environment In general, the AppStream environment behaves like a Windows desktop computer running a single application, Horta. Because it’s running in a browser, though, there are some important differences. Many of them are managed via the AppStream toolbar at the top of the screen.\nData import and export: file system and clipboard Web browsers are constrained with respect to how they read and write data on a computer, and applications running in virtual machines displayed in a browser, even more so.\nFile system access: the third icon from the left opens a dialog showing “My Files”, and within it, a “Temporary Files” location. This is a file location on the remote computer running Horta and Horta can read and write to. You can then transfer files from that location to your local computer via the “My Files” dialog box. See “Importing Data” and “Exporting Data” in the “Basic Operations” section for more details.\nClipboard access: if you copy anything in Horta to the clipboard, it’s only accessible on the remote computer. The fourth icon from left on the toolbar will transfer the remote clipboard’s contents to the local clipboard.\nWindows and screens Horta users often want to see the 2D and 3D views simultaneously, or they want a maximum 3D view while leaving room for the Data Explorer and/or Horta Control Center. To enable use of multiple monitors, click the seventh icon from left on the toolbar. There is also a full-screen mode enabled via the sixth icon.\nThe second icon on the toolbar shows all windows, in case you undock a Horta Window and then lose it behind a larger window. There’s also a terminal window from which Horta is initially run; this can be ignored. If you close it, it will close Horta.\nQuitting and relaunching Horta Sometimes Horta does have issues. Often reloading data by reopening a workspace will clear them up. If not, to relaunch the application again without ending the AppStream session, choose File \u003e Exit or click the “x” at top right. Then relaunch the application by clicking the first icon in the toolbar and choosing “Horta Workstation” again.\nEnding the session To end the session, you can choose “End Session” from the drop-down menu on the top-right toolbar button.\nRemember that when you end a session, some data that is stored on the remote computer will be lost:\nVolatile data:\nfiles in “MyFiles/Temporary Files” information on the clipboard All other data (sample data, workspace data, annotations, notes, etc.) is stored in the database and is not lost when a session ends.\nData safety during development HortaCloud is still under development!\nthere is some risk of database loss during upgrades any neurons should be exported to SWC for safety some settings/preference data will be lost when sessions end this will be moved into the database in a future release ","categories":"","description":"Some general information about running HortaCloud in the AppStream environment\n","excerpt":"Some general information about running HortaCloud in the AppStream …","ref":"/docs/user_manual/appstream_basics/","tags":"","title":"AppStream Basics"},{"body":"The recommended way to deploy HortaCloud is to use Amazon Web Services (AWS), but you can also deploy the Horta services locally on your own client/server machines.\nUsing Docker Swarm, you can choose to deploy on two or three servers. The primary benefit of using three servers is that the MongoDB cluster will have a complete replica set for high availability.\n","categories":"","description":"Learn how to deploy a Horta instance on your own servers\n","excerpt":"Learn how to deploy a Horta instance on your own servers\n","ref":"/docs/administration/bare_metal/","tags":"","title":"Bare metal"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/","tags":"","title":"Documentation"},{"body":" This document describes a Janelia Workstation deployment intended for setting up a personal development environment. Unlike the canonical distributed deployments which use Docker Swarm, this deployment uses Docker Compose to orchestrate the services on a single server.\nNote that this deployment does not build and serve the Workstation client installers, although that could certainly be added in cases where those pieces need to be developed and tested. In most cases, however, it is expected that this server-side deployment be paired with a development client built and run directly from IntelliJ or NetBeans.\nSystem Setup This deployment should work on any system where Docker is supported. Currently, it has only been tested on Scientific Linux 7 and macOS Mojave.\nTo install Docker and Docker Compose on Oracle Linux 8, follow these instructions.\nClone This Repo Begin by cloning this repo:\ngit clone https://github.com/JaneliaSciComp/jacs-cm.git cd jacs-cm Configure The System Next, create a .env.config file inside the jacs-cm directory. This file defines the environment (usernames, passwords, etc.) You can copy the template to get started:\ncp .env.template .env.config vi .env.config At minimum, you must customize the following:\nConfigured the UNAME and GNAME to your liking. Ideally, these should be your username and primary group. Setup REDUNDANT_STORAGE and NON_REDUNDANT_STORAGE to point to directories accessible by UNAME:GNAME. If you want to use the defaults, you may need to create these directories and set the permissions yourself. Set HOST1 to the hostname you are deploying on. If possible, use a fully-qualified hostname – it should match the SSL certificate you intend to use. Fill in all the unset passwords with \u003e8 character passwords. You should only use alphanumeric characters, special characters are not currently supported. Generate 32-byte secret keys for JWT_SECRET_KEY and MONGODB_SECRET_KEY. Enable Databases (optional) Currently, Janelia runs MongoDB outside of the Swarm, so they are commented out in the deployment. If you’d like to run the databases as part of the swarm, edit the yaml files under ./deployments/jacs/ and uncomment the databases.\nInitialize Filesystems The first step is to initialize the filesystem. Ensure that your REDUNDANT_STORAGE (default: /opt/jacs), NON_REDUNDANT_STORAGE (default: /data) directories exist and can be written to by your UNAME:GNAME user (default: docker-nobody). If you are using Docker for Mac, you’ll need to take the additional step of configuring share paths at Docker -\u003e Preferences… -\u003e File Sharing. Add both REDUNDANT_STORAGE and NON_REDUNDANT_STORAGE and then click “Apply \u0026 Restart” to save your changes.\nNext, run the filesystem initialization procedure:\n./manage.sh init-local-filesystem You should see output about directories being created and initialized. If there are any errors, they need to be resolved before moving further.\nOnce the initialization is complete, you can manually edit the files found in CONFIG_DIR. You can use these configuration files to customize much of the JACS environment.\nSSL Certificates At this point, it is strongly recommended is to replace the self-signed certificates in CONFIG_DIR/certs/* with your own certificates signed by a Certificate Authority:\nsudo cp /path/to/your/certs/cert.{crt,key} $CONFIG_DIR/certs/ sudo chown docker-nobody:docker-nobody $CONFIG_DIR/certs/* If you use self-signed certificates, you will need to set up the trust chain for them later.\nExternal Authentication The JACS system has its own self-contained authentication system, and can manage users and passwords internally.\nIf you’d prefer that users authenticate against your existing LDAP or ActiveDirectory server, edit $CONFIG_DIR/jacs-sync/jacs.properties and add these properties:\nLDAP.URL= LDAP.SearchBase= LDAP.SearchFilter= LDAP.BindDN= LDAP.BindCredentials= The URL should point to your authentication server. The SearchBase is part of a distinguished name to search, something like “ou=People,dc=yourorg,dc=org”. The SearchFilter is the attribute to search on, something like “(cn={{username}})”. BindDN and BindCredentials defines the distinguished name and password for a service user that can access user information like full names and emails.\nStart All Containers Now you can bring up all of the application containers:\n./manage.sh compose up -d You can monitor the progress with this command:\n./manage.sh compose ps Initialize Databases If you are running your own databases, you will need to initalize them now:\n./manage.sh init-databases Verify Functionality You can verify the Authentication Service is working as follows:\n./manage.sh login You should be able to log in with the default admin account (root/root), or any LDAP/AD account if you’ve configured external authentication. This will return a JWT that can be used on subsequent requests.·\nIf you run into any problems, these troubleshooting tips may help.\nUpdating Containers Containers in this deployment are automatically updated by Watchtower whenever a new one is available with the “latest” tag. To update the deployment, simply build and push a new container to the configured registry.\nStop All Containers To stop all containers, run this command:\n./manage.sh compose down Build and Run Client Now you can checkout the Janelia Workstation code base in IntelliJ or NetBeans and run its as per its README.\nThe client will ask you for the API Gateway URL, which is just http://$HOST1. In order to automatically connect to your standalone gateway instance, you can create a new file at workstation/modules/Core/src/main/resources/my.properties with this content (replacing the variables with the values from your .env.config file):\napi.gateway=https://$HOST1 ","categories":"","description":"How to deploy HortaCloud to your own local server\n","excerpt":"How to deploy HortaCloud to your own local server\n","ref":"/docs/development/composedeployment/","tags":"","title":"Single server deployment"},{"body":"This document describes the canonical two-server Janelia Workstation deployment for supporting neuron tracing for the MouseLight project at the Janelia Research Campus and other research institutions. This deployment uses Docker Swarm to orchestrate prebuilt containers available on Docker Hub.\nDeployment Diagram Hardware Setup The JACS backend consists of several services which need to be deployed on server hardware. We have tested the following configuration:\nTwo Dell PowerEdge R740XD Servers Each server has 40 cores (e.g. Intel Xeon Gold 6148 2.4G) Each server has 192 GB of memory The hard drives are configured as follows: 2 x 200GB SSD in RAID1 - Operating system (/) 2 x 960GB SSD in RAID1 - Databases, user preferences, etc. (/opt) 12 x 10TB in RAID6 - Image files (/data) The rest of this guide assumes that you have two server hosts dedicated to deploying this system, which are configured as listed above. They will be referred to as HOST1 and HOST2.\nThis two-server deployment can support 5-10 concurrent users. We use the following configuration for client machines:\nDell Precision 5820 Tower Minimum of 8 cores (e.g. Intel Xeon W-2145 3.7GHz) 128 GB of memory Nvidia GTX1080Ti 11GB (reference card, blower fan style) Other similar cards will work fine: GTX1070, GTX1080, RTX2080 Windows 10 Install Oracle Linux 8 The backend software runs on any operating system which supports Docker. However, Oracle Linux is used at Janelia and has been extensively tested with this software. Therefore, we recommend installing the latest version of Oracle Linux 8.\nInstall Docker To install Docker and Docker Compose on Oracle Linux 8, follow these instructions.\nSetup Docker Swarm On HOST1, bring up swarm as a manager node:\ndocker swarm init On HOST2, copy and paste the output of the previous command to join the swarm as a worker.\ndocker swarm join --token ... All further commands should be executed on HOST1, i.e. the master node. One final step is to label the nodes. Each node needs the “jacs=true” label, as well as “jacs_name=nodeX”.\ndocker node update --label-add jacs_name=node1 $(docker node ls -f \"role=manager\" --format \"{{.ID}}\") docker node update --label-add jacs_name=node2 $(docker node ls -f \"role=worker\" --format \"{{.ID}}\") docker node update --label-add jacs=true $(docker node ls -f \"role=manager\" --format \"{{.ID}}\") docker node update --label-add jacs=true $(docker node ls -f \"role=worker\" --format \"{{.ID}}\") Finally, you can run this command to ensure that both nodes are up and in Ready status:\ndocker node ls Download the installer Download the installer and extract it onto the master node, as follows. VERSION should be set to the latest stable version available on the releases page.\nexport VERSION=\u003cversion_number_here\u003e cd /opt sudo mkdir deploy sudo chown $USER deploy cd deploy curl https://codeload.github.com/JaneliaSciComp/jacs-cm/tar.gz/$VERSION | tar xvz ln -s jacs-cm-$VERSION jacs-cm cd jacs-cm Configure The System Next, create a .env.config file inside the intaller directory. This file defines the environment (usernames, passwords, etc.) You can copy the template to get started:\ncp .env.template .env.config vi .env.config At minimum, you must customize the following:\nSet DEPLOYMENT to mouselight. Ensure that REDUNDANT_STORAGE and NON_REDUNDANT_STORAGE point to the disk mounts you used during the operating system installation. Alternatively, you can make symbolic links so that the default paths point to your mounted disks. Set HOST1 and HOST2 to the two servers you are deploying on. Use fully-qualified hostnames here – they should match the SSL certificate you intend to use. Fill in all the unset passwords with \u003e8 character passwords. You should only use alphanumeric characters, special characters are not currently supported. Generate 32-byte secret keys for JWT_SECRET_KEY, MONGODB_SECRET_KEY, JACS_API_KEY, and JADE_API_KEY. If you want to enable automated error reporting from the Workstation client, set MAIL_SERVER to an SMTP server and port, e.g. smtp.my.org:25. Deploy Services Now you can follow the Swarm Deployment instructions to actually deploy the software.\nImport Imagery If you have your own imagery, you will need to convert it before importing.\nEach brain image is referred to as a “sample”. You should place each sample in $DATA_DIR/jacsstorage/samples on one of the servers. If you place the sample on the first server, in $DATA_DIR/jacsstorage/samples/\u003csampleDirectoryName\u003e, then in the Workstation you will refer to the sample as /jade1/\u003csampleDirectoryName\u003e.\nAs a side note if you use ’lvDataImport’ service to generate the imagery, the service does not use JADE to persist the data. So if you need the data to be on a storage that is only accessible on certain hosts, JACS must run on that host in order to be able to write the data to the corresponding location. If that is not an option you can generate the data to a temporary location then move it to the intended sample directory.\nIn the Workstation, select File → New → Tiled Microscope Sample, and then set “Sample Name” to \u003csampleDirectoryName\u003e and “Path to Render Folder” as /jade1/\u003csampleDirectoryName\u003e.\nOpen the Data Explorer (Window → Core → Data Explorer) and navigate to Home, then “3D RawTile Microscope Samples”, and your sample name. Right-click the sample and choose “Open in Large Volume Viewer”. The 2D imagery should load into the middle panel. You should be able to right-click anywhere on the image and select “Navigate to This Location in Horta (channel 1)”, to load the 3D imagery.\nFind More Information This concludes the MouseLight Workstation installation procedure. Further information on using the tools can be found in the User Manual.\n","categories":"","description":"How to deploy Horta to a pair of servers\n","excerpt":"How to deploy Horta to a pair of servers\n","ref":"/docs/administration/bare_metal/twoserverdeployment/","tags":"","title":"Two-server deployment"},{"body":"This section will walk you through the process of tracing a neuron and some other tasks. It’s meant to introduce you to the basic operations of Horta. Not all features or details of features are discussed. You can find those details in the appropriate Feature section.\nAssumptions Before you get started with Horta, it is assumed:\nThe data is available in the proper format. If a sample hasn’t been created, you know the file path to the data. (HortaCloud) You have a HortaCloud username and password. (desktop) The Janelia Workstation is installed, you have a username and password, and you have logged in after launching the workstation. You have set the memory used by the workstation to a large number, preferably 40G or more. You’ve read the Concepts section of this documentation. You should contact whomever prepared your data if you don’t know the answers to the above questions.\nData Explorer and Data Inspector When Horta is launched (either version), you will see the Data Explorer and Data Inspector at the left edge of the application window.\nThe Data Explorer panel lists all of the objects in the workstation that the user has permission to view. These objects include both samples and workspaces as well as folders used to organize them.\nSingle-clicking on an object in the Explorer will populate the Data Inspector with more details about the object. The Attributes tab shows object metadata. Permissions shows current access permission and, via the “Grant permission” button at the bottom, allows the user to share read or write (edit) permissions for the selected object. The Annotations tab is only used in the desktop application for datatypes not available in HortaCloud.\nRight-clicking on an object brings up a menu of actions. Most are self-explanatory; others will be described later in this section or in one of the reference sections.\nBasic annotation The most basic workflow for neuron tracing is this:\nCreate a sample Create a workspace Create a neuron Add points to the neuron When done, export the neuron Those tasks, and others, are detailed below.\nCreating a sample A sample is the representation of a dataset in the workstation. This only needs to be created once per dataset and can be shared among all users who are annotating that dataset. You need to create a sample in order to view data.\nHortaCloud In HortaCloud, samples are usually already created automatically by the system. File menu \u003e New \u003e Tiled Microscope Sample In “Sample Name”, enter a name for the sample In “Path To Render Folder”, enter the path that the image server will use to locate the images. This should be a Linux-style path. (HortaCloud) The sample path will refer to a S3 bucket. Click “Add Sample”. The sample will appear in your “3D Tile Microscope Samples” in your home folder. You may need to refresh the Data Explorer to see it. (optional) Share the data with other users or groups. Once it’s been created, you may perform any operations on the sample that you can do with any other object in the workstation. For example, you may move, rename, or remove it. See the main workstation documentation for details.\nRelocating a sample If, for any reason, the images for a sample change location or change name, you can update the path stored in the sample without recreating it. Right-click on the sample and choose “Edit sample path”.\nViewing and navigation Opening a sample In the Data Explorer, browse to the sample. Right-click the sample and choose “Open in Horta”. This option loads both samples and workspaces. The sample will open the Horta Control Center, which is typically docked at the right-hand side of the main window. When you open a sample (rather than a workspace), very little information will appear in the Horta Control Center. To view the images in the sample, click the checkbox next to “Open 2D” or “Open 3D” near the top of the Horta Control Center (see screenshot below). The viewer (2D or 3D) will open in the center panel. Depending on the data volume, network speed, and disk speed, the data may take anywhere from a few seconds to a few minute to open. The status bar at the bottom of the application will indicate some of the loading steps. The 2D and 3D viewers each have their own tab, and you can switch between them freely. After you’ve created a workspace (see below), use the same procedure to open the workspace.\nViewing and navigating in the Horta 2D viewer Horta 2D displays the 3D data as a series of 2D planar images. It provides the usual suite of tools for viewing and navigating through the data. When zoomed out, a lower-resolution view of the data is displayed. When zoomed in, higher resolution images are loaded. Annotations are displayed when they are near the plane that is currently being displayed.\nHortaCloud 2D data In HortaCloud, usually only the lowest resolution of the 2D data is available. When a sample or workspace is loaded, a single image of the whole data set will be displayed at the lowest zoom level. If you zoom in, the image will become blurry. The toolbar at the top of Horta 2D (screenshot above) indicates the current mouse mode. Usually it’s the “pen mode” shown above, which is used for normal annotation. Hover the mouse cursor above each mode to get a description of what they do. This section assumes you are in “pen mode”. Holding down “option” will change to “hand mode” while the key is held down. This mode is useful for navigation.\nTo pan the image, hold down option so hand mode is active, then left click and drag the image. Alternately, double-click the image in either mode to recenter at the selected point. To zoom the image, do any of: hold down shift and use the mouse scroll wheel, drag the slider to the right of the image, click “Zoom Min” or “Zoom Max”, or (when zoom mode is selected from the toolbar) left-click to drag the area to zoom to. To change planes, do any of: drag the slider under the image, click the arrows in the plane number indicator under the image, or scroll the mouse wheel when it is in plane change mode. Note that when you are zoomed out, each click of the mouse wheel will traverse more than one plane. Note that holding down the shift key will put the mouse scroll wheel into zoom mode, and releasing the shift key will place the mouse scroll wheel into plane change mode, regardless of the mode the mouse scroll wheel was in when the shift key was depressed. The “Reset View” button will recenter the image in x, y, and z and zoom out. In the Horta Control Center, the “Go to…” button allows you to enter an x, y or x, y, z location, and the view will move to center itself at that point. If you don’t enter z, the plane doesn’t change. Commas are optional. Square brackets around the coordinates are ignored. Adjusting colors in Horta 2D Controls for adjusting the color of each channel in the image appear below the image, below the plane slider.\nEach channel can be shown or hidden (eye icon at far left), and its color can be change (color patch at far right, which will open a color choice dialog).\nThe three handles on each slider control the range of color mapped to the range of data. The three locks below the sliders will force each of those values to remain in sync across all channel individually.\nAt the bottom of the panel to the right of the 2D view area are two color-related buttons. The “Auto Contrast” button attempts to find a reasonable range of colors based on a simple histogram of the data. This almost never does a good job. The “Reset Colors” button returns the displayed color of each channel to its default value (ie, sliders at maximum, etc.). This is also rarely useful.\nNote that the current colors, contrast settings, channel visibility and locks are not saved automatically! You must manually save changes by clicking on the gear menu and choosing “Save Color Model To Workspace” or “Save Color Model As User Preference”. As the desired settings usually depend on the characteristics of the individual sample, usually you will want to save the color model to the workspace, after which it will be automatically loaded when the workspace is opened. However, if you find there is a baseline color model you’d prefer over the default (sliders set to min/middle/max), you may save to your preferences as a personal default.\nOn the same menu are options for saving or loading the color to/from disk.\nViewing and navigating in Horta 3D The Horta 3D viewer is opened by clicking the checkbox next to “Open 3D” from within the Horta Control Center. At low zoom, lower resolution images are displayed. When zoomed in, higher resolution images are loaded. Annotations are displayed at all zoom levels.\nTo move around the volume:\nSingle-left click anywhere (including on an annotation): center the volume on that point. Note that if you click on an annotation or near signal, Horta will find the depth in z of the point and center on it correctly. This allows you to follow a neuron by clicking along its length with minimal depth changing. Left-click and drag: move the viewpoint in the view plane. Middle-click and drag: rotate the volume Scroll wheel: change the zoom level Right-click anywhere and choose “Reset Horta rotation” if you would like to return to the original image orientation. In the Horta Control Center panel, the “Go to…” button just above the neuron list allows you to enter an x, y or x, y, z location, and the view will move to center itself at that point. If you don’t enter z, the plane doesn’t change. Commas are optional. Square brackets around the coordinates are ignored. Horta 2D and Horta 3D view synchronization If both viewers are open, you may synchronize the views by right-clicking on a point in either viewer and choosing “Synchronize Views at This Location”. This command moves the point to the center of the screen in each view. The zoom level is not changed.\nAdjusting colors in Horta 3D Adjusting colors and the general appearance of the data in Horta 3D can be challenging. Horta 3D has been tested and used with one or two data channels. The mixing feature especially may not work with more channels.\nBasic settings To make basic color adjustments in Horta 3D, Windows menu \u003e Horta \u003e Color sliders. In the window that appears, you can adjust color sliders as you would for the Horta 2D. Usually you will want to hide the third channel in this case.\nUnmixing Often the two data channels are used to display a desired signal in one channel and a reference in the other channel. However, fluorescence from the reference channel can also appear in the signal channel. Subtracting it out can make the signal substantially more distinct. To make use of this feature:\nAdjust the signal and reference channels independently (see note below) with the third channel hidden (click the eye to the right of the third slider) Right-click and choose Tracing channel \u003e Unmix channel 1 using current brightness (or 2, depending on which channel is which) Hide the first two channels and unhide the third Adjust the third channel’s contrast and brightness Note: finding good contrast/brightness settings for the first two channels so the unmixing works well is quite difficult! In general, you should set the channel color slider for the signal channel so the brightest part of the signal (usually the soma) is oversaturated and work from there.\nColor model settings are saved as in 2D (see Adjusting colors in Horta 2D above). Note that this saves a wider array of setting than for Horta 2D, including rendering options!\nNavigating to neurons or annotations Once you’ve begun annotation, you can easily navigate to neurons or their constituent annotations (see below for how to annotate).\nNeurons: If you double-click on a neuron name in the neuron list, the view will center on the center of the neuron’s bounding box. Note that if a neuron spans a lot of area and you are zoomed in, you may not see any of the actual neuron!\nAnnotations: If you double-click on an annotation in the annotation list, the view will center on the annotation.\nBasic tracing and editing Annotations are stored in workspaces. A workspace is associated with a sample, which contains the images. You must create a workspace before annotating. Multiple workspaces may be associated with the same sample. For example, multiple people may trace the same neuron independently as a quality control check. Alternatively, a single workspace may be shared among multiple users, usually tracing different neurons simultaneously.\nIn general, only one tracer should be working on any given neuron at the same time, to prevent one tracer’s work from being overwritten by another’s. Horta attempts to prevent this from happening, but it is possible.\nNote Most editing and tracing tools are containing in the Horta Control Center panel at right. If you’re working on a small display, you may need to use the panel’s scroll bar to make some of the lower tools visible.\nCreating a workspace To create a workspace:\nOpen a sample from the Data Explorer; it will appear in the Horta Control Center. In the workspace controls at the top of the editor panel at right (see screenshot above), click the “+” button. Fill in the desired name for the workspace. By default, it has a structured name based on the date and other data. You may optionally click “Manual override” to name the workspace whatever you would like. (Note that “Assign neurons” has no effect for this method of creating a workspace.) The workspace will be created, and it will automatically immediately load in the Horta Control Center. The workspace name and sample name will appear in the workspace controls area. The workspace will also appear in the Data Explorer under “Workspaces” in your home directory (you may need to refresh the explorer). Once the workspace has been created, you can open it again just like you’d open a sample, by right-clicking the workspace in the Data Explorer and choosing “Open in Horta”. Operations on workspaces You can perform a number of operations on the workspace. Some of these operations are common to all data in the workstation; these operations can be performed from the Data Explorer, typically by right-clicking on the workspace. These operations include moving, sharing, renaming, deleting the workspace.\nOther operations are specific to Horta. These operations can be accessed by clicking the gear icon in the Horta Control Center, in the workspace information panel just above the neuron list. Most of these will be discussed in other sections.\nSave as: If you need to make a copy of the workstation and all the annotations within it, choose “Save as…” from the workspace gear menu. You will be prompted for a new name just as if you were creating the workspace from scratch.\nCreating or deleting a neuron Annotations are contained within neurons. Typically a neuron in Horta represents one biological neuron. Usually its root annotation is placed on the neuron’s soma. Neurons may contain more than one annotation tree, however. For example, it can be convenient to trace large arbors individually and link them later. Neuron controls and the neuron list are located below the workspace controls in the Horta Control Center (screenshot below).\nTo create a neuron:\nOpen a workspace. Click the “+” button below the neuron list. Type in a name for the neuron and click “OK”. The new neuron will appear in the neuron list, selected. To delete a neuron, select a neuron in the list, then click the “-” button below the neuron list. You will be shown a dialog box to confirm your decision.\nAnnotating in Horta 2D To add points to a neuron in the Horta 2D viewer:\nOpen a workspace. Create a neuron if one does not exist. In the neuron list, select a neuron by clicking on it. Be sure you have the pen tool selected in the toolbar; this is the default, and it is rarely changed. If there are no points in the neuron: Shift-left-click a location to place a point at that location. If there are already points in the neuron: Select the parent annotation you want to add a child to by clicking on it. The annotation will then be drawn with a “P” on it. Navigate to the location of the next annotation, possibly changing planes as you do. Shift-click the location where the annotation should be placed. A new point will be added, connected to its parent, and the new point will become the parent annotation for the next annotation added. In Horta 2D, this point is marked with a “P”. The view will re-center on the new point. Continue adding points by shift-clicking Annotating in Horta 3D Adding points to neurons in the Horta 3D viewer is somewhat different than in the Horta 2D viewer because of the third dimension. In Horta 2D, when you add a point, it is added at the z-coordinate of the plane you are viewing. In Horta 3D, though, you are looking at a three-dimensional representation of the data, so a mouse-click might correspond to a number of locations in the data corresponding to various depths into the screen.\nSnap to signal: However, Horta 3D provides the user with assistance in placing annotations on signal. When you move the mouse cursor in Horta 3D, if it nears a bright signal (hopefully a labelled neuron and not background noise), the mouse cursor will change to a ball with a “+” sign, and it will jump to the center of the brightness automatically. If you shift-click to place a point, that point will be placed in three dimensional space on top of the brightest part of the data. In this way, you can annotate correctly in three dimensions without having to determine the exact depth of the signal manually.\nNote that the “snap to signal” feature depends on which image channel has signal, and is therefore channel-dependent! Right-click and choose “Tracing channel” to determine whether signal is sought in the raw channels or a combination of multiple channels (average or unmixing; see above for unmixing details).\nThe complete procedure is then:\nOpen a workspace. Create a neuron if one does not exist. Open the Horta 3D viewer In the Horta Control Center, in the neuron list, select a neuron by clicking on it. If there are no points in the neuron: Shift-left-click a location to place a point at that location in the LVV. (need to replace this with horta 3D version!) Navigate to the location you want to annotate in Horta 3D. Select the parent annotation you want to add a child to by clicking on it. The annotation will then be drawn with a “P” on it. Navigate to the location of the next annotation, possibly rotating as you do. Move the mouse cursor to the location. A ball cursor with a “+” sign should appear. Shift-click the location. Note that if there is no bright signal, the “+” cursor will not appear, and you will not be able to place an annotation! A new point will be added, connected to its parent, and the new point will become the parent annotation for the next annotation added. This point is marked with a ball with a “P” on it. The view will re-center on the new point. Continue adding points by shift-clicking Editing neurons Horta contains several useful tools for manipulating neurons and annotations. Most of these operations are performed by right-clicking an annotation and choosing from the pop-up menu in one of the viewers. Some of the more commonly used actions are:\nMouse \u0026 keyboard actions:\nSet next parent: left-click an selected annotation to set it to be the parent for the next added annotation Move annotation: to move an annotation, left-click and drag it to a new location Merge neurites: to merge one fragment with another, left-click and drag an annotation on top of another annotation; after a confirming dialog, the two neurites will be linked together between those two annotations The first neurite, with the dragged annotation, becomes a branch of the second annotation Note! The tolerance for this operation is quite small! This is best done zoomed quite far in. Delete annotation: to delete the “next parent” annotation, press the delete key; this acts like the “Delete link” function, below; if no annotation is deleted, nothing happens Right-click menu actions (as named on the menu):\nDelete link: deletes the clicked annotation; connects the annotation’s parent and child; can’t be used on branch points Delete subtree rooted at this anchor: deletes the clicked annotation and all annotations below it in the tree Split anchor: add a new annotation located between the clicked annotation and its parent; this annotation can then be dragged to a new location; this is used to annotate more densely after the fact Split neurite: break the neurite (neuron fragment) apart by removing the link between the clicked annotation and its parent; the clicked annotation becomes a root annotation Changing neuron appearance Color: You can change the color of each neuron’s annotations by clicking on the colored square in the neuron list (“C” column), by right-clicking the neuron in the neuron list and choosing “Change neuron color…”, or by right-clicking on one of its annotations and choosing “Change neuron color…”. In either case, you’ll be presented with a dialog box that lets you choose the neuron color. If you choose “Change neuron color…” from the gear menu under the neuron list, you will change the color of all neurons currently visible in the neuron list.\nVisibility: It’s often useful to hide some or most neurons from view. There are a variety of controls for accomplishing that.\nTemporary: To temporarily hide all neurons, hold down the “v” key. This function is useful for viewing the data under a neuron, often as it’s being annotated.\nPersistent: Neurons can be toggled between visible and invisible (shown or hidden) for the duration of the annotation session (until the workspace is reloaded). There are multiple ways to do this:\nRight-click on an annotation and choose “Hide neuron”. Click the eye icon in the “V” column in the neuron list; this column also indicates the current visibility of each neuron (open or closed eye). Right-click the neuron name in the neuron list and choose one of the hide/show neurons options (show all, hide all, or hide all except the clicked neuron). On the gear menu below the neuron list, choose one of the hide/show neurons options (show all, hide all, or hide all except the currently selected neuron). This will apply to all neurons currently displayed in the list Filtering neurons The neuron list usually displays all neurons in the workspace, but its contents can be filtered to a subset of neurons, which is especially useful when the list is long.\nText filter: As you type characters into the box (2-3 or more), the list will update to show only neurons whose names contain the entered text somewhere in the name. Java regular expressions can be used. Ignore prefix: As you type characters into the box, the list will update to show only neurons whose names do not begin with the entered text. Again, regular expressions can be used. Tag filter: Neurons can be included or excluded from the displayed list based on their tags. See the “Tags” section in Horta Features. Spatial filter: When there are a large number of neurons (hundreds or more), perhaps computationally generated, performance can suffer if all of them are visible. Neurons can be filtered by spatial proximity to a neuron of interest. See the “Spatial Filtering” section in Horta Features. Note that any actions triggered from the gear menu below the neuron list will only act on neurons that are currently visible in the list! In this way, you can, for example, easily change colors or visibility of a specific subset of neurons.\nThe sort order of the neurons can be changed by choosing “Sort” from the neuron gear menu.\nFiltering annotations The annotation list is located below the neuron list in the right-hand panel. By default, it displays annotations that are “interesting”: roots, branch points, end points, and any annotation with notes (see below). Note that the “geo” column is meant to suggest the neuron’s geometry (see below). They are ordered by last update time (newest at the bottom). Only annotations from the currently selected neuron are shown.\nsymbol geometry o-- root --- link --\u003c branch --o end Filter menu and buttons: The filter menu lets you switch between several pre-determined filters (with buttons provided to quickly switch to some of those filters without navigating the menu).\nNote that some of these filters do not operate the way you’d think! They are designed to assist tracers to locate specific classes of annotations in conjunction with the note system (see below) and one possible workflow.\nfilter included annotations default roots, branches, ends, annotations with a note ends endpoint that do not have a note “traced end” or “problem end” (ie, an endpoint that needs to be traced out = unfinished endpoint) branches has “branch” note (ie, manually marked as a place that should be a branch point) roots is a root node notes has any note geometry roots, branches, ends interesting has “interesting” note review has “review” note Filter text: As you type characters into the box, the list will update to only show annotations whose note contains the entered text somewhere in the note. Regular expressions may be used. Note that this filter also operates on the “geometry” column! For example, if you type o–- in the text filter, you will only see root annotations. This can also be done via the menu (above), but it may be useful in some cases.\nAdding notes (text annotations) Arbitrary text notes may be added to any annotation. To bring up the dialog box for adding, editing, or deleting notes: right-click on the annotation and choose “Add, edit, or delete note…”, double-click on the “note” column in the annotation list corresponding to the annotation, or select the annotation and press the assigned keyboard shortcut. In the dialog that pops up, you may enter any text you like. You may also edit or delete the note from this dialog.\nPredefined notes: There are a set of buttons that insert predefined notes (such as “branch”, “interesting”, and “review”). The predefined notes interact in important ways with the annotation filters. The details are described in the “Notes” section of Horta Features.\nNotes are imported and exported along with the neurons (see below).\nChanging neuron ownership There are two kinds of ownership in Horta. First is the ownership that is managed by the Janelia workstation itself. The items that appear in the Data Explorer (workspaces and samples) are shared using the “Permissions” tab in the Data Inspector window. A tracer must have write access to the workspace before annotating. (This is usually only relevant when sharing workspaces. A tracer always has write access to workspaces they create.)\nThe ownership of individual neurons, by contrast, is managed within Horta itself. The “O” column of the neuron list displays an icon corresponding to the neuron’s owner: an icon of a head for another user, an icon of a computer for a generic “system” group, and nothing (no icon) for the current user. In all cases, if you hover your mouse over the icon (or empty space without an icon), a tooltip will show the full name of the owner.\nFirst of all, most operations are prohibited when a neuron is owned by another user or a group that the current user is not a member of. This includes adding or deleting points or notes. Changing color or visibility is allowed, however, and those changes will not be seen by others.\nSecond, if a neuron is owned by a group, then any member of that group may make any changes to that neuron. When they do, they will also become the owner of the neuron automatically.\nYou may change the owner of a neuron if you own it, you are a member of the group that owns it, or you are designated as an administrator of the group that owns the workspace.\nTo change the owner of a neuron, single-click in the “O” column corresponding to the neuron in the neuron list.\nThis will be an icon or an empty space. From the dialog box, choose a new owner (user or group) for the neuron. To change the owner for multiple neurons, filter the neuron list to the desired set of neurons, then choose “Choose neuron owner…” from the gear menu under the neuron list.\nAdmins in the system may change any neuron’s owner at any time.\nThe workspace gear menu contains the very dangerous “Temp ownership admin” checkbox which gives the user the ability to change neuron ownership as if they were an admin (but grants no other admin privileges). Use this sparingly! It’s intended for use by a trusted and professional group to circumvent situations where a neuron owner is, eg, on vacation, and no admin is available to change it.\nExporting data Horta use the SWC file format for importing and exporting neuron data. It’s a multi-column text file that records the position and connectivity of the neurons and not much else. Note that an SWC file may contain more than one neuron or neuron fragment.\nTo export all of the neurons in a workspace, choose “Export SWC file” from the gear menu in the workspace information area. To export one specific neuron, right-click on the neuron name in the neuron list and choose “Export SWC file…”. To export all neurons in the neuron list (potentially filtered), from the gear menu under the neuron list, choose “Export neurons…”. Output files: In all cases, you will be prompted to choose an output location for the exported neuron(s).\nIf you are exporting one neuron, it will be saved in the chosen location. If you are exporting more than one neuron, two versions of the data will be exported: A single SWC named for the workspace that contains all of the neurons. A folder named for the workspace that contains one SWC file for each individual neuron. Options: When exporting neurons, there are two options on the right side of the location choosing dialog box:\nPoint density: This option can be ignored unless you are using automatically traced paths (described elsewhere). Click “Help” for more info. Export notes: When this option is checked, any notes (text annotations) on the neuron are also exported in a JSON file. The file has the same name as the SWC file but uses the .json file extension instead of .swc. See the Horta Reference section for details on the SWC and note file formats.\nImporting data SWC files may be imported into Horta either interactively or in the background. Because importing large numbers of neurons can be time-consuming, importing more than a dozen or so neurons should be done in the background if you want to use Horta while the files are imported.\nInteractive Because an SWC file may store one or more than one neuron per file, and in Horta, you may have multiple neuron fragments per neuron, there are two ways to handle the import. Both of these options are found on the gear menu under the workspace information area.\nImport SWC file as one neuron: This option reads all neurons in the SWC file(s), creates a single neuron, and places all neurons in the file in the newly created neuron (as what Horta calls neurites). Import SWC file as separate neurons: This option reads all neurons in the SWC file(s) and creates one neuron per root in the file(s). Multiple files: In either case, you may choose either a single SWC file or a folder containing multiple SWC files. In the latter case, all SWC files in the folder are imported. Files in subfolders are not imported.\nNote: If the SWC file was exported from Horta and has an associated .json notes file, the notes will automatically be imported with the neurons.\nBackground SWC files, especially large numbers of them, may be imported into a workspace that will be created for them in the background (on the server).\nThe SWC files to be imported must be collected in a folder that can be read by the workstation server.\nRight-click on the sample in the Data Explorer Choose “Import Linux SWC Folder into new Workspace on Sample” Give the new workspace a name in the first dialog box (optional) Click the “Assign Neurons” box and provide a user or group that will be the owner of all the newly imported neurons In the second dialog, enter the Linux file path to the folder containing the neurons. (optional) There is a redundant check box to assign all neurons to the default common user group. In principle, this can be done from the previous dialog box as well. After clicking OK, the import process will begin. It may show its progress in the “Background Tasks” tab. Do not attempt to load or use the workspace until the task completes! Note that the import process will continue (on the server) even if you quit the workstation!\nImportant note: Unlike the interactive case, subfolders are recursively traversed, and all SWC files are imported!\nHortaCloud imports and exports Because HortaCloud running via AppStream does not have direct access to the computer’s hard drive, a two-step process must be used for importing and exporting SWC files and their associated JSON notes files. The process uses the “My Files” location in AppStream, which is a location for temporary files that last for the length of an AppStream session. If you click on the “My Files” folder icon on the top AppStream toolbar (screenshot below), a dialog box will open up. If you click on “Temporary Files”, it will open a folder where you can upload (via the button or by dragging) or download files (by clicking the downward-pointing arrow next to the filename). This “Temporary Files” location is visible from Horta, within any file dialog. So the process for importing SWC files is:\nOpen “My Files”, then “Temporary Files”. Upload SWCs by clicking “Upload Files” or by dragging. In Horta, choose one of the SWC import options (see above), and navigate to “Temporary Files” in the file dialog. Export works the same way, in reverse: export to “Temporary Files”, then download from there.\n","categories":"","description":"Description of some basic operations: how to navigate images, how to trace neurons in 2D and 3D, and how to import and export neuron data\n","excerpt":"Description of some basic operations: how to navigate images, how to …","ref":"/docs/user_manual/basic_operations/","tags":"","title":"Basic Operations"},{"body":" We are in the process of writing this documentation.\n","categories":"","description":"Guide for developing HortaCloud code\n","excerpt":"Guide for developing HortaCloud code\n","ref":"/docs/development/","tags":"","title":"Developer's guide"},{"body":"This document describes the full three-server Janelia Workstation deployment for supporting both FlyLight and MouseLight at Janelia Research Campus. This deployment uses Docker Swarm to orchestrate containers available on Docker Hub.\nMultiple environments are supported with this deployment:\nprod dev Deployment Diagram Hardware Setup This guide assumes that you have three high-end servers which can be dedicated to running Docker Swarm. We use 40-core servers with at least 192 GB of RAM. YMMV.\nWe’ll refer to the three deployment hosts as HOST1, HOST2, and HOST3.\nNote that an additional server or VM is necessary to run the JACS Async Services outside of Docker, if you are planning to submit image processing jobs to an HPC cluster, such as with the Image Processing Pipeline (IPP).\nInstall Oracle Linux 8 The backend software should run on any operating system which supports Docker. However, Oracle Linux is used at Janelia and has been extensively tested with this software. Therefore, we recommend installing the latest version of Oracle Linux 8. Previously, we used Scientific Linux 7 and that is also known well although it’s no longer supported.\nInstall Docker To install Docker and Docker Compose on Oracle Linux 8, follow these instructions.\nSetup Docker Swarm On HOST1, bring up swarm as a manager node, and give it a label:\ndocker swarm init On HOST2 and HOST3, copy and paste the output of the previous command to join the swarm as a worker.\ndocker swarm join --token ... All further commands should be executed on HOST1, i.e. the master node. One final step is to label the nodes. Each node needs the “jacs=true” label, as well as “jacs_name=nodeX”. You can find out the node ids by running docker node ls.\ndocker node update --label-add jacs_name=node1 \u003cid of HOST1\u003e docker node update --label-add jacs_name=node2 \u003cid of HOST2\u003e docker node update --label-add jacs_name=node3 \u003cid of HOST3\u003e docker node update --label-add jacs=true \u003cid of HOST1\u003e docker node update --label-add jacs=true \u003cid of HOST2\u003e docker node update --label-add jacs=true \u003cid of HOST3\u003e Download the installer Download the installer and extract it onto the master node, as follows. VERSION should be set to the latest stable version available on the releases page.\nexport VERSION=\u003cversion_number_here\u003e cd /opt sudo mkdir deploy sudo chown $USER deploy cd deploy curl https://codeload.github.com/JaneliaSciComp/jacs-cm/tar.gz/$VERSION | tar xvz ln -s jacs-cm-$VERSION jacs-cm cd jacs-cm Configure The System Next, create a .env.config file inside the installer directory. This file defines the environment (usernames, passwords, etc.) You can copy the template to get started:\ncp .env.template .env.config vi .env.config At minimum, you must customize the following:\nEnsure that REDUNDANT_STORAGE and NON_REDUNDANT_STORAGE point to the disk mounts available on the local systems. Alternatively, you can make symbolic links so that the default paths point to your mounted disks. Set HOST1, HOST2, and HOST3 to the servers you are deploying on. Use fully-qualified hostnames here – they should match the SSL certificate you intend to use. Fill in all the unset passwords with \u003e8 character passwords. You should only use alphanumeric characters, special characters are not currently supported. Generate 32-byte secret keys for JWT_SECRET_KEY and MONGODB_SECRET_KEY. Enable Databases (optional) Currently, Janelia runs MongoDB outside of the Swarm, so they are commented out in the deployment. If you’d like to run the databases as part of the swarm, edit the yaml files under ./deployments/jacs/ and uncomment the databases.\nDeploy Services Now you can follow the Swarm Deployment instructions to actually deploy the software.\nDeploy ELK for monitoring To deploy an ELK stack for monitoring follow ELK Deployment.\nFind More Information This concludes the MouseLight Workstation installation procedure. Further information on using the tools can be found in the User Manual.\n","categories":"","description":"How to deploy Horta to three servers\n","excerpt":"How to deploy Horta to three servers\n","ref":"/docs/administration/bare_metal/fulldeployment/","tags":"","title":"Three-server deployment"},{"body":"This section discusses Horta features. It contains both details of basic operations that are covering in the previous section as well as descriptions of features that haven’t yet been discussed.\nGlobal Preferences/settings There are a number of customization options for Horta.\nHortaCloud In HortaCloud, choose Tools \u003e Options. Desktop If you’re running Windows, choose Tools \u003e Options if you’re running Windows. On a Mac, the settings are called “Preferences” and are in the traditional place under the application menu at top right. Here are some settings of interest:\nCore \u003e Application: Max Memory (desktop): This should be set to a high number, preferably 40G or more. Max Memory (HortaCloud): This should be left blank; the system will set the memory correctly. Horta \u003e Application: “Use http for file access”: Must be left checked. “Load last opened sample…”: This option is not currently working. “Verify neurons on load” is never needed under normal circumstances. It can be enabled to check for some internal inconsistencies in neurons stored in the database. “Use anchors-in-viewport” should be left enabled. This is a graphics optimization. See below for “Click mode for adding annotations” “Z-slice thickness”: The 2D view shown in Horta 2D actually shows annotations from multiple planes. This setting determines the depth of this effect. If you increase the number, annotations become visible on a large number of surrounding planes. Note however that there are some subtle behaviors in how the data and annotations are rendered, and changing this value dramatically away from its default value may not have the effect you want. Horta \u003e Tile Loading: In general, you can leave “Concurrent tile loads” and “Number of tiles to cache” to their defaults. Larger numbers may improve tile loading in Horta 3D. See below for “Click mode for adding annotations” Keymap: This section shows all of the user-changeable keyboard shortcuts for the Janelia workstation, including Horta. The shortcuts are listed by section. New shortcuts will take effect after the application is restarted. Note that some keyboard shortcuts in Horta cannot be changed from this dialog. Unfortunately, there is no central list of what they are. Click mode for adding annotations By default, to add annotations in Horta 2D and 3D, you select a parent annotation, then you shift-left-click on the desired location. For some people, holding down the shift key while making repeated annotations may cause stress on their hands, fingers, or wrists when done over a long period of time. For that reason, an option is provided to change that gesture to a simple left-click to add annotation (with no shift key). Note that this is set independently for Horta 2D and Horta 3D. The two settings are in different subpanels for historical reasons.\nNote that if the “left-click” option is selected, some other behaviors in the two viewers will change, specifically those involving left-clicks. Most notably, in Horta 2D, idle clicks when (for example) closing right-click menus will register as an annotation.\nGenerally speaking, using the default group names:\nall users should be a member of workstation_users all users who want to interact with Horta samples or annotations should be a member of mouselight all regular Horta tracers should also be a member of mouselight_tracers; this group is used to populate some dialog boxes regarding neuron ownership, and project leadership, collaborators, and other non-tracers need not be in this group (it’ll clutter the menus) User and group administration If you are an administrator, you can Windows \u003e Core \u003e Administration tool to manage users and groups. Note that these are users and groups within the Horta or Janelia Workstation applications. For HortaCloud, there is a second layer of users and administrator for AppStream that are managed separately.\nAn administrator within the Horta or Janelia Workstation system has a lot of power.\nsee all data and assign permissions for all data set privileges for all users and groups use Tools \u003e Admin \u003e Run as… to connect as any user (usually used for debugging purposes) You should limit the number of people with admin privileges.\nHorta Control Center features Notes Notes are text annotations that are attached to point annotations. They can be added, edited, or deleted from a dialog box triggered by a right-click on the annotation and choosing “Add, edit, delete note”. The contents can be arbitrary.\nHowever, the note dialog does provide several pre-defined notes that can be used to support a simple tracing workflow. In addition, some of those pre-defined notes have specific effects on other operations and on the annotation filters.\npredefined note intended use behavior traced end to be added when the signal at that point has been traced as far as it can; it’s a “done” marker must be placed on an endpointif another point is placed as a child, it’s automatically removeddoes not appear in the “ends” filter branch to be added when the tracer finds a point where signal branches but doesn’t want to follow the branch at that time; it’s a “come back to this” marker cannot be placed on an existing branch if another point is placed to make it an actual branch, it’s automatically removed does not appear in the “branches” filter interesting indicates a point of interest no special behavior review indicates a point that needs review by a second set of eyes, supervisor, or expert no special behavior problem end indicates an endpoint that may or may not be able to be traced further by the current user; it’s a “done (but problematic)” marker must be placed on an endpoint if another point is placed as a child, it’s automatically removed does not appear in the “ends” filter (arbitrary text) the user may place arbitrary text at any point no special behavior All together, the notes and filters together were designed to support the following workflow: - start tracing at a soma or a segment of interest - add point along the segment - at a branching point in the signal, add the “branch” note to the annotation to mark it as a point to be revisited; there is then no need to place a single point on the second branch to find it later - when a branch ends in a synapse or becomes too faint to trace, place a “traced end” or “problem end” note, indicating that the tracing is complete for this branch - if those notes are added consistently, then the “branches” and “ends” filters will identify those locations that need further work - when those two filters have no annotations in them, the neuron is done\nTags Tags are user-defined, usually short, labels that are applied to neurons.\nTo add or remove tags from a single neuron, right-click on the neuron in either the Horta 2D view or the neuron list and choose “Edit neuron tags”. The left “Applied” column contains tags that have already been applied to the neuron. Click on a tag in this column to removed it. The right “Available” column contains existing tags that can be applied to the neuron by clicking on them. To define a new tag, type the tag in the box below the “Available” column and click “New tag”. It will be created and applied immediately. The list of “available” tags is the list of tags that exist on any neuron, plus two special tags. The “auto” tag may be used freely. It is suggested to use this tag to mark neurons that were created by some automated process, to distinguish them from human-created neurons. When automatically created neurons are numerous, this can be used to filter them out (See “Spatial filter”). The “hidden” tag is used internally and shouldn’t be used. To add or remove a tag from multiple neurons, choose “Edit tags” from the gear menu in the neuron list. The tag will be added or removed from all the neurons in the filtered list, if applicable. Tags can be used to filter the neuron list by either including or excluding neurons with a single tag. Tags can be used to control a few useful toggle behaviors. This feature is called “Neuron group properties”.\nFirst, add a tag to one or more neurons of interest using one of the above methods. Right-click on a neuron and choose “Edit neuron group properties”. The dialog box shows each user-applied tag as a “Neuron group” and indicates how many neurons are in the group. Click on the cell in the third column of a row corresponding to a tag to assign a hotkey for the toggle. Click on the fourth column to assign a toggleable property. Click save. Now when keyboard focus is in Horta 2D, the hot key will toggle the property: Radius: the radii of the neuron(s) in Horta 3D will be toggled between their set size (either default or user-set) and a very thin radius Visibility: the hotkey will hide or show the neurons(s) Background: when this is toggled on, the neuron is placed in a “background” state that can be seen but not interacted with (ie, you cannot move, select, or add points to a background neuron) Crosscheck: this is the same as “background” and “radius” together; it’s designed to have a neuron visible but unobtrusive and unchangeable Note that this feature has been buggy in the past; sometimes you need to save repeatedly before the setting holds. Shared workspaces \u0026 the Neuron Broker: updates When multiple users open and work in the same workspace, the Neuron Broker on the server acts as the intermediary for all changes to the database.\nIt ensures that changes occur one at a time, in order. It prevents users from changing neurons they do not own. It broadcasts the results of changes to all users, so users in the same workspace can see changes made by other users. There are two elements of the UI that relate to the operation of the Neuron Broker.\nFirst, if “Shared Updates” is unchecked in the UI (in the right side panel of the Horta 2D view), then changes in the workspace will not be displayed until the “Refresh” button is clicked (same panel). This can be useful in the rare occasions that so many updates are arriving that it affects local performance. Normally, this should be left on. Second, if the name of a neuron in the neuron list becomes italicized, that is an indication that the data in the workstation has become unsynchronized with the data in the database for that neuron. If you hover the mouse over the neuron name, it will tell you how many changes are not synced. Generally, if this occurs and does not clear after a minute or two, you should reopen the workspace. The unsynced changes will be lost, but the workspace will then be fully in sync with the database. See also “Changing neuron ownership” in the Horta Features section.\nSpatial filtering When a workspace has a large number of neuron fragments, such as those created by an automated segmentation process, two negative consequences may occur. First, the display becomes visually cluttered, and second and more important, performance of all kinds can degrade. These problems can be alleviated by only loading and displaying a small subset of all fragments in the region where the tracer is working. To enable spatial filtering:\nClick the gear menu under the neuron list and choose “Set Neuron Filter Strategy”. The first check box enables or disables the filter. In all cases, only fragments owned by the tracing group are affected. Neurons owned by tracers (current tracer or other tracers) will always be loaded. There are currently two options for the filter: Proximity: fragments will be loaded if they are close to any non-fragment neuron. Selection: fragments will be loaded if they are close to the last selected annotation. Distance: in either strategy, this controls how close fragments need to be to the target neuron(s) or point in order to be loaded. Task workflow \u0026 Neuron Cam This feature is still being developed and will be documented later.\nMovie Maker and Scene Editor The Horta Movie Maker is designed to created fly-through movies, typically for presentations. It is not supported and not documented at this time.\nMore Horta 2D features Right-click operations Horta 2D has a number of operations on its right-click menu. Many of them are described elsewhere, especially in the Horta Basic Operations section. We will quickly summarize most of the operations here. Operations that are not documented below fall into two categories. First, some of them are redundant with other parts of the UI and are likely to be removed from the menu. For example, “Begin new neurite here” is unnecessary on the right-click menu. That operation is also documented in the Horta Basic operation section. Second, if an operation is not documented anywhere, it is deprecated and likely to be removed entirely, not just from this menu. Some of these will be noted explicitly.\nRight-click in empty space Some options appear when you click in empty space in the 2D view, with no annotation under the mouse pointer.\nScroll through Sample (Z): The camera will move to the lowest plane (smallest z) at the mouse pointer location and smoothly move through the planes until it reaches the highest plane. The zoom level is not changed. File: All the operations on this menu are deprecated and should not be used. Copy (various): When any of these options are selected, information about the location of the mouse pointer is copied to the clipboard. Note that for HortaCloud, the data is copied to the AppStream clipboard, and you must click the icon in the toolbar to copy it to the clipboard of your local computer Micron coords: the x, y, z location in µm in this form: [75556.8, 43819.6, 23460.8] Octree location: the location in the file hierarchy of the 2D tile under the mouse pointer. See the Horta Reference section for more details on the file layout. The format is this: /5 Raw file tile location: the file path to the raw microscope tile that produced the rendered data under the mouse pointer, if available. Octree filepath: the file path to the rendered tile under the mouse pointer. Task Workflow: see below View: The view submenu replicates a number of buttons on the Horta 2D toolbar and side navigation panel. It is redundant and likely to be removed at some point in the future. Right-click on an annotation If you right-click on an annotation in Horta 2D, a longer set of operations appears in addition to those described above. Note that an annotation will become visibly slightly larger when the mouse pointer is over it, indicating that the annotation will be the target of the click. Again, some of the operations are either deprecated or may be removed from the menu.\nTrace path to parent: generate an automatically traced path from the selected annotation to its parent (see “Automatic point refinement and tracing”, below) Delete subtree: deletes the annotation under the mouse pointer and all annotations in the tree below it Delete link: deletes the annotation under the mouse pointer if it is an endpoint, an isolated single point, or a point with a single parent and child (in which case the parent and child are connected). You cannot delete a branch point or a root point with children; use “delete subtree” instead. Merge chosen neurite…: see “Smart merge” below Transfer neurite: As described in Horta Concepts, a “neurite” is a structure rooted at a single root annotation, while a “neuron” is a container that may hold several neurites. This operation moves the selected neurite to another existing neuron (chosen from a dialog), or to a newly created neuron, which you are prompted to name. Split anchor: This operation creates a new annotation between the selected annotation and its parent, placed close to the selected annotation. It’s used to increase the density of points in the neuron. Split neurite: This operation splits the current neurite into two, with the selected annotation cut from its parent into a new root. Add, edit, delete note: See “Notes” section below. Edit neuron tags/group properties: See “Tags” section below. Generate neuron review tree/Select point in Task View: See “Task workflow” section below. Set neuron radius: This operation allows the user to set the radius associated with the annotation. By default it is set to 1.0 µm. Automatic point refinement and path tracing Desktop only These features only work in the desktop version of Horta. HortaCloud data does not contain the high-resolution 2D data needed to make them work.\nIf you are working on a rare dataset that does have the full 2D octree in HortaCloud, it should work.\nAutomatic point refinement: This option can be toggled on and off from the gear menu in the workspace information area. It only applies to Horta 2D. When this feature is toggled on, annotations will be placed at the x, y location of the click as usual. However, the annotation will be placed on the z-plane which has the brightest signal in the first channel within five planes of the click. Automatic path tracing: This option can be toggled on and off from the gear menu in the workspace information area. When this feature is toggled on, when the user adds a new annotation, Horta 2D places an additional set of annotations between the new annotation and its parent. The “automatic path” is calculated automatically to follow the signal in three dimensions in the first channel using an A-* (A-star) algorithm. The details are contained in the reference section. The points are placed densely, approximately one pixel apart. These paths are also drawn in a different style than the links between manually-placed points. While the toggle is active, the paths are automatically recalculated whenever any manually-placed annotation changes. So if an annotation is moved by hand, all of the links to its parent and children will be updated with new automatic paths. If you are using this feature, you should place annotations not too far apart. The algorithm is limited so it will not run more than a handful of seconds, and if points are too far apart, the algorithm may not find a path before it runs out of time. These points may be exported as other points are. The “Export SWC” dialog contains one option to let you control how many points are exported. The “Point density” value should be set to 0 if you don’t want to export any automatically placed points, set to 1 if you want to export all of them, or to a positive integer n if you want to export every nth point. Note that you may request an automatic path tracing from an annotation to its parent explicitly from the right-click annotation menu.\nSmart merging Note: this feature is experimental!\nWhen presented with a large number of neuron fragments that must be assembled into reconstructed neurons, such as those provided by automated image analysis, the amount of time merging each neuron pair should be minimized. The “smart merge” feature tries to make it easier for the user to do a large number of repeated merges.\nTo use this feature, select any point on the first neuron fragment. Then right-click on any point in the second neuron fragment and choose “Merge chosen neurite to selected neurite”. Horta 2D will attempt to find the two endpoints in the two fragments that are closest. Horta 2D will then move the point selection (the next parent selection) to the farthest endpoint in the merged neuron. Arrow key navigation You may navigate along the neuron backbone in Horta 2D using the arrow keys. With a point in a neuron selected (set as next parent), pressing an arrow key moves the selection to another point and recenters the screen on that point.\nRight arrow: moves to the next branch point or endpoint farther away from the neuron root; if there are multiple possible branches, the first is followed (see below) Left arrow: moves to the previous branch point or root toward the root Alt + left/right arrow: as before, but move by only one point instead of until next branch/root/end Up/down arrows: In general, the up and down arrows move you among parallel branches When on a neuron segment that has another segment in parallel (another segment with the same branch point parent), move to the next such branch in sequence, positioned at the first point beyond the branch point. When on a branch point or root, or segment without parallel branches, does nothing. The order of branches in all cases (“first” for right arrow, or parallel branches for up/down arrow) is determined by the order the children of the branch appear in internal data structures Other The “Volume cache” checkbox and “Clear cache” button to the right of the 2D view area should generally be ignored.\nDesktop Since the desktop version of Horta uses the full 2D octree, prolonged browsing in the 2D view can fill up the 2D tile cache. Usually the system will clear its cache automatically, but in rare cases, when the cache is near full, the system will spend too much time managing the cache relative to loading tiles, and performance will suffer. When noticing a slowdown in tile loading, the user can press “Clear Cache”, and this may alleviate the issue. More Horta 3D features Right-click operations Horta 3D has a number of operations on its right-click menu. As with Horta 2D, some appear only when you right-click over an annotation, and others appear all the time. The options that always appear relate to display, and they are described below in “Display options”.\nThe operations that pertain the the annotation (anchor) or neuron under the mouse pointer replicate the corresponding functions in Horta 2D’s UI (see above).\nDisplay options There are a number of view options that can be adjusted in Horta. Many of them are located on the right-click menu under “View”.\nView \u003e Projection Maximum Intensity Projection (MIP) is the default display projection mode in Horta. MIP projection provides a robust, informative view of volumetric imagery data, under a wide variety of brightness settings. Occluding projection (“true” volume rendering) can convey a better sense of relative depth, compared to MIP, which can be useful for discriminating neurites that approach one another closely in space. The downside of this superior display quality is that it is very sensitive to the exact brightness settings. The user should probably adjust the brightness settings (Window-\u003eHorta-\u003eBrightness), especially the minimum intensity value, before switching to the “Occluding” mode. View \u003e Rendering Filter Horta provides three sub-voxel filtering options: Nearest Neighbor, Trilinear, and Tricubic. These filtering options can be used to trade off speed for image quality.\nNearest-neighbor filtering shows the individual voxels of the raw image tile as discrete blocks. This mode is not particularly useful for visualization, but it is fast, and it is very useful for debugging, and for directly demonstrating the true spatial resolution of the underlying imagery data. Trilinear filtering, the default option, interpolates between adjacent voxel intensities using a fast hardware-accelerated computation. This is a good compromise between render speed and image quality. Tricubic interpolation is significantly slower than trilinear interpolation, but yields a smoother appearance, which can make it easier to see the true structure of the tissue being observed. Other View options View \u003e Stereo3D lets you choose between multiple methods of displaying images if you have appropriate 3D hardware support. View \u003e Compress voxels in z: This option, when checked, compresses voxels in the z direction to make them appear more cubic. Normally, the data has a worse resolution in z, giving the image volume a stretched look. The user may choose which appearance they prefer. View \u003e Save viewer settings: If you make changes to the color sliders, tracing channel settings, or any other Horta view settings, you must choose this command to save those changes. Note: unlike Horta 2D color model settings, which are saved with the workspace, these settings are save on a per-user basis! If you switch to another workspace, the same Horta color settings will be used. Tracing channel: As described in Horta Basic operation, annotation in Horta 3D is assisted by Horta 3D’s “Snap to Signal” feature. This menu allows the user to choose which channel or combination of channels will be used to determine signal brightness. Tiles The tiles submenu controls loading of the 3D data tiles. Note that in normal operation, tiles are loaded automatically as you navigate through the volume, typically displaying 5-8 tiles surrounding the last mouse click.\nTiles \u003e Load Horta Tile at Cursor/Focus: Force load a tile at either the center of the screen (Focus) or the location of the mouse cursor; occasionally useful if the automatic algorithm isn’t doing what you want. Tiles \u003e Prefer rendered ktx tiles: When checked, Horta will prefer to load the ktx file format tiles. This is the default; ktx tiles load much faster than the alternative raw tiles. If this setting is unchecked, raw tiles, if available, will be loaded instead. Note that you must save viewer settings and restart the application if you change this setting. Tiles \u003e Clear all volume blocks: Choosing this operation forces all tiles to be discarded from the screen and cache and reloaded. Auto-load image tiles: When checked, tiles are loaded automatically as you navigate; when unchecked, you must manually specify load of each desired tile using the other operations (Load at Cursor or Focus). Normally the user will not change any of these options or use any of these operations.\nHorta 3D auxiliary windows Horta 3D has a number of panels containing a variety of supplemental controls. They can be opened from the Window menu \u003e Horta. All of them can be undocked, moved, and redocked anywhere you like.\nHorta 2D, Horta 3D: opens the view window but does not load any data (if data has already been loaded, it will be visible) Camera Control: provides another way to control the camera in Horta 3D Center focus, rotation, and zoom: replicate mouse commands View Slab: adjusts how thick the visible slab of data is; the default preset II shows a nice chunk of data; preset I shows a very thin slab, closely resembling the 2D view Color Sliders: used to adjust the color settings for the image data channels and the tracing channel (as described in Horta Basic operation Movie Maker and Scene Editor: not supported or documented Graphics Speed: used for debugging; displays some graphics performance data ","categories":"","description":"Horta features\n","excerpt":"Horta features\n","ref":"/docs/user_manual/features/","tags":"","title":"Features"},{"body":"To install Docker on a server running Oracle Linux 8, some special configuration is needed. Much of this comes from the official documentation.\nPrerequisites First, make sure that Docker isn’t already installed:\nyum list installed | grep docker Remove any existing installations before proceeding.\nEnsure that /opt (or whatever disk is to be used for Docker data) is formatted with the d_type option. You can find out like this:\n$ xfs_info /opt meta-data=/dev/mapper/vg0-lv_opt isize=512 agcount=4, agsize=5701632 blks = sectsz=4096 attr=2, projid32bit=1 = crc=1 finobt=0 spinodes=0 data = bsize=4096 blocks=22806528, imaxpct=25 = sunit=0 swidth=0 blks naming =version 2 bsize=4096 ascii-ci=0 ftype=1 log =internal bsize=4096 blocks=11136, version=2 = sectsz=4096 sunit=1 blks, lazy-count=1 realtime =none extsz=4096 blocks=0, rtextents=0 If the above says ftype=0, then the filesystem will need to be recreated (reference).\nInstalling Docker sudo yum install -y yum-utils sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo sudo yum install -y docker-ce If this fails with error messages like package containerd.io-1.4.3-3.2.el8.x86_64 conflicts with runc provided by runc then you may have conflicting packages installed already. Try removing them like this:\nsudo yum erase podman buildah Post Install Configuration To avoid running out of space on the root partition, you should configure docker to point to /opt/docker (reference):\nsudo mkdir -p /opt/docker sudo chown root:root /opt/docker sudo chmod 701 /opt/docker Next, configure Docker to use the overlay2 storage driver (reference).\nCreate a file at /etc/docker/daemon.json with this content:\n{ \"data-root\": \"/opt/docker\", \"storage-driver\": \"overlay2\" } You should also create a local user called “docker-nobody” with UID 4444, which can be used for running containers without root.\nsudo groupadd -g 4444 docker-nobody sudo useradd --uid 4444 --gid 4444 --shell /sbin/nologin docker-nobody Finally, you can start Docker:\nsudo systemctl enable docker sudo systemctl start docker Installing Docker Compose You’ll also need to install the Docker Compose executable:\nsudo curl -L \"https://github.com/docker/compose/releases/download/1.23.2/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose Note that there are newer versions of the Docker Compose, but they have bugs that prevent them from working with our scripts. Please use the version above to ensure compatibility.\n","categories":"","description":"How to install Docker on Oracle Linux 8\n","excerpt":"How to install Docker on Oracle Linux 8\n","ref":"/docs/administration/bare_metal/installingdocker/","tags":"","title":"Installing Docker"},{"body":"This document assumes that you have downloaded and configured the installer according to one of the deployment guides.\nThe following steps are common to all Docker Swarm deployments of the Workstation.\nInitialize Filesystems The first step is to initialize the filesystems on all your Swarm systems. On each server, ensure that your REDUNDANT_STORAGE (default: /opt/jacs), NON_REDUNDANT_STORAGE (default: /data) directories exist and can be written to by your UNAME:GNAME user (default: docker-nobody).\nThen, run the Swarm-based initialization procedure from HOST1:\n./manage.sh init-filesystems You can manually edit the files found in CONFIG_DIR to further customize the installation.\nOnce the initialization completes you can just run:\n./manage.sh stop Also it is a good idea to stop the initialization stack if anything goes wrong before you try it again.\nSSL Certificates At this point, it is strongly recommended is to replace the self-signed certificates in $CONFIG_DIR/certs/* on each server with your own certificates signed by a Certificate Authority:\n. .env sudo cp /path/to/your/certs/cert.{crt,key} $CONFIG_DIR/certs/ sudo chown docker-nobody:docker-nobody $CONFIG_DIR/certs/* If you continue with the self-signed certificates, you will need to set up the trust chain for them later.\nExternal Authentication The JACS system has its own self-contained authentication system, and can manage users and passwords internally.\nIf you’d prefer that users authenticate against your existing LDAP or ActiveDirectory server, edit $CONFIG_DIR/jacs-sync/jacs.properties and add these properties:\nLDAP.URL= LDAP.SearchBase= LDAP.SearchFilter= LDAP.BindDN= LDAP.BindCredentials= The URL should point to your authentication server. The SearchBase is part of a distinguished name to search, something like “ou=People,dc=yourorg,dc=org”. The SearchFilter is the attribute to search on, something like “(cn={{username}})”. BindDN and BindCredentials defines the distinguished name and password for a service user that can access user information like full names and emails.\nStart All Containers Next, start up all of the service containers. The parameter to the start command specifies the environment to use. The dev environment uses containers tagged as latest and updates them automatically when they change. The prod deployment uses a frozen set of production versions. When in doubt, use the prod deployment:\n./manage.sh start It may take a minute for the containers to spin up. You can monitor the progress with this command:\n./manage.sh status At this stage, some of the services may not start because they depend on the databases. The next step will take care of that.\nInitialize Databases Now you are ready to initalize the databases:\n./manage.sh init-databases It’s normal to see the “Unable to reach primary for set rsJacs” error repeated until the Mongo replica set converges on healthiness. After a few seconds, you should see a message “Databases have been initialized” and the process will exit successfully.\nYou can validate the databases as follows:\nVerify that you can connect to the Mongo instance using ./manage.sh mongo, and run show tables Connect to the RabbitMQ server at http://HOST1:15672 and log in with your RABBITMQ_USER/RABBITMQ_PASSWORD Restart Services Bounce the stack so that everything reconnects to the databases:\n./manage.sh stop ./manage.sh start Now you shoult wait for all the services to start. You can continue to monitor the progress with this command:\n./manage.sh status If any container failed to start up, it will show up with “0/N” replicas, and it will need to be investigated before moving further. You can view the corresponding error by specifying the swarm service name, as reported by the status command. For example, if jacs_jade-agent2 fails to start, you would type:\n./manage.sh status jacs_jade-agent2 Verify Functionality You can verify the Authentication Service is working as follows:\n./manage.sh login You should be able to log in with the default admin account (root/root), or any LDAP/AD account if you’ve configured external authentication. This will return a JWT that can be used on subsequent requests.\nIf you run into any problems, these troubleshooting tips may help.\nManage Services As long as your Docker daemon is configured to restart on boot, all of the Swarm services will also restart automatically when the server is rebooted.\nIf you want to remove all the services from the Swarm and do a clean restart of everything, you can use this command:\n./manage.sh stop To pull and redeploy the latest image for a single service, e.g. workstation-site:\n./manage.sh restart jacs_workstation-site Configure Crontabs The following crontab entries should be configured in order to perform periodic maintenance automatically. It’s easiest to install the crontabs on the docker-nobody account:\nsudo crontab -u docker-nobody -e Database maintenance refreshes indexes and updates entities permissions:\n0 2 * * * /opt/deploy/jacs-cm/manage.sh dbMaintenance group:admin -refreshIndexes -refreshPermissions SOLR index refresh (if using SOLR):\n0 3 * * * /opt/deploy/jacs-cm/manage.sh rebuildSolrIndex Database backups (if using containerized databases):\n0 4 * * * /opt/deploy/jacs-cm/manage.sh backup mongo Install The Workstation Client Now that the services are all running, you can navigate to https://HOST1 in a web browser on your client machine, and download the Workstation client. Follow the installer wizard, using the default options, then launch the Workstation.\nIf you are using the default self-signed certificate, you will need to take some extra steps to install it on the client.\nIf you are using LDAP/AD integration, you should be able to log in with your normal user/password. If you are using the Workstation’s internal user management, you must first login as user root (password: root), and then select Window → Core → Administrative GUI from the menus. Click “View Users”, then “New User” and create your first user. Add the user to all of the relevant groups, including MouseLight.\nOptional: Adding NFS Storage If you have data on NFS, and those NFS drives can be mounted on the MouseLight hosts, that data can be made available to the Workstation.\nFirst, create a file at deployments/mouselight/docker-swarm.prod.yml which looks like this:\nversion: '3.7' services: jade-agent1: volumes: - /path/to/your/nfs:/path/to/your/nfs:ro,shared jade-agent2: volumes: - /path/to/your/nfs:/path/to/your/nfs:ro,shared This will expose the path to both JADE agent containers. Now you need to configure the JADE agents to serve this data. On both hosts, edit /opt/jacs/config/jade/config.properties and add the following:\nStorageVolume.mouseLightNFS.RootDir=/path/to/your/nfs StorageVolume.mouseLightNFS.VirtualPath=/path/to/your/nfs StorageVolume.mouseLightNFS.Shared=true StorageVolume.mouseLightNFS.Tags=mousebrain,light StorageVolume.mouseLightNFS.VolumePermissions=READ You can use any name you want instead of mouseLightNFS. Then you should add this name to StorageAgent.BootstrappedVolumes:\nStorageAgent.BootstrappedVolumes=jade1,mouseLightNFS You will need to bounce the service stack to pick up these changes.\n","categories":"","description":"Deploying the JACS services using Docker Swarm\n","excerpt":"Deploying the JACS services using Docker Swarm\n","ref":"/docs/administration/bare_metal/swarmdeployment/","tags":"","title":"Deploying JACS"},{"body":"Import/export file formats SWC The swc file format is a standard format for recording neuron skeletons. Unfortunately, while the basic format is widely used, there is no single standard for defining the format, and as a result, there are differences in implementation among various swc writers and readers. The basic spec can be seen here.\nIn summary, an SWC file:\nis a text file contains a number of header lines, each beginning with a ‘#’ character followed by a list of points, one per line, with parents preceding children Each line consists of seven numbers separated by whitespace in the following order: id type x y z radius parent, with:\nfield value id integer identifying the point, in ascending order type integer indicating the type of the previous segment, with: 0 = undefined 1 = soma 2 = axon 3 = dendrite 4 = apical dendrite 5 = fork point 6 = end point 7 = custom x, y, z floating point coordinates of the point radius floating point radius of the previous segment parent id value of the parent for the current point; a root point has parent = -1 Notes:\ntwo fields are non-critical for rendering the basic neuron skeleton: the type field describes but does not affect connectivity and can usually be ignored the radius field does not affect connectivity; it’s only necessary if you are rendering neuron volumes (skeletons with width) a node’s id must appear in the id column before it appears as a parent; that is, child nodes must appear lower in the list than parent nodes Janelia-specific details Only nodes with type 5 and 6 are marked by Horta, as they are the only types that can be inferred from geometry at export time. All other points are marked as type 0. On import, the type column is ignored. Coordinates and radii are assumed to be in microns. A few headers are used by Horta: ORIGINAL_SOURCE, a fairly standard header, is set to “Janelia Workstation Large Volume Viewer” That is the original name for the software, back when it was only 2D, and we decided not to change this identifier. The x, y, z locations of the nodes are centered on the origin at export time because not all SWC viewers can handle the large coordinates (Horta can). The header field OFFSET gives the x, y, z offset needed to reproduce the original annotation location. The values are whitespace-delimited floating point numbers. Horta correctly handles this field during its own import and export; it will always use the field on export, but it doesn’t complain if it’s missing on import. If an swc reader ignores this header, the neuron will be of correct shape but shifted in space from its original location. The color of the exported neuron (optional) is recorded in the header field COLOR as a comma-separated list of floating point RGB values ranging from 0 to 1. Other headers are ignored at import. The name of the neuron is not stored inside the swc file. However, when imported, the neuron will be named like the swc file. Here is an example swc file:\n# ORIGINAL_SOURCE Janelia Workstation Large Volume Viewer # OFFSET 76290.282407 42379.443335 23460.277313 # COLOR 0.501961,0.000000,1.000000 1 0 -870.258314 84.790733 0.000000 1.000000 -1 2 0 -408.096941 6.007367 0.000000 1.000000 1 3 5 54.064431 -72.775998 0.000000 1.000000 2 4 0 232.512856 -256.688292 0.000000 1.000000 3 5 6 600.186790 -429.961032 0.000000 1.000000 4 6 0 159.078322 142.548313 0.000000 1.000000 3 7 6 232.512856 526.078910 0.000000 1.000000 6 JSON When neurons are exported from Horta in swc format, any notes attached to the neuron’s points are also exported. The notes are contained in a JSON file of the same name as the swc file but with a “.json” extension. The JSON file contains a dictionary with the following fields:\nworkspaceID: contains the integer workspace ID number username: contains the workstation username of the user doing the export offset: contains a list of floating point numbers [x, y, z] holding the offset as described in the section above neurons: contains a list of dictionaries, one per neuron exported; each dictionary has fields: neuronID: contains the integer neuron ID number notes: contains a list of neuron notes; each note is a list of [x, y, z, note] on import, the username and workspace and neuron IDs are ignored The x, y, z, coordinates of each note will match the coordinates of the corresponding annotation in the corresponding swc file, as they use the same offset system. Horta automatically imports and exports the JSON files when the swc files are imported or exported.\nHere is an example JSON file that corresponds to the above example swc file:\n{ \"workspaceID\" : 2229358932059488401, \"username\" : \"olbrisd\", \"neurons\" : [ { \"neuronID\" : 2653026075256291473, \"notes\" : [ [ 232.51285642151197, 526.0789095035507, 3.637978807091713E-12, \"traced end\" ], [ 232.51285642151197, -256.68829229611583, 3.637978807091713E-12, \"interesting\" ] ] } ], \"offset\" : [ 76290.28240663109, 42379.443335160235, 23460.2773125 ] } Image file formats Raw tiff stacks The raw microscope data is stored in tiff stacks. They can be displayed in Horta 2D on demand, but they are typically used only in rare instances when stitching in the rendered images is not perfect. Typically this data is only available in the desktop version of the software at the site the sample was imaged.\nDetails of the files and their organization will be added later.\nRendered 2D images The raw microscope data is transformed and stitched together into a contiguous rendered whole. It’s also stored in tiff stacks, rendered at multiple resolutions and arranged in an octree. For HortaCloud, this data likely only has the a single low-resolution image for each channel.\nDetails of the files and their organization will be added later.\nHorta 3D images (ktx files) Horta’s 3D images are optimized for fast loading into the Horta viewer. The ktx file format is designed to load directly into graphics cards. In order to keep the files both small enough to load rapidly and small enough to economically store, the rendered data is transformed and down-sampled before ktx tile creation. These files are also arranged in an octree, although currently Horta only uses the highest resolution images.\nThe file format is managed by the Khronos Group and is described here.\nHorta-specific details will be added later.\nA* algorithm for automatically traced paths The algorithm for computing the path is:\nExtract a rectangular solid block of voxels containing the two endpoints, plus a small buffer region in all three dimensions. (Thus, if the neuron meanders outside of this block, the technique will not work well. Try to choose anchors with relatively straight connections between them.) Measure the variation in voxel intensity within that block: record mean and standard deviation. Currently, only the first channel is examined! Assume that the background (non-neuron) intensities follow a normal distribution, with the measured parameters (mean and standard deviation). Define the path weight for a particular voxel, as the probability that an intensity greater than or equal to the voxel intensity, could have arisen randomly from the background distribution. Thus dim voxels get a large path weight, and bright voxels get a small path weight. This value can get extremely small for very bright pixels (think 10 raised to the minus seventy power). You can think of this weight as (1.0 minus the probability this voxel is a neuron), assuming all voxels are either background or neurons. weight = erf( (intensity - mean) / (standard_deviation) ), where erf() is the error function. Because it uses the mean and standard deviation of intensities, this method of path weighting is robust in the face of large uniform intensity bias offsets, like we sometimes see in the mouse brain imagery. Use the A* (A-star) algorithm to compute the lowest cost path connecting the two endpoints. This path is guaranteed to be optimal. The algorithm will be terminated if it takes more than 10 seconds to finish. User groups for ownership purposes There are two user groups in the workstation that are used in neuron ownership operations. They are set at compile time to values specified in the console.properties file.\nconsole.LVVHorta.tracersgroup=group:mouselight console.LVVHorta.activetracersgroup=group:mouselight_tracers The “tracersgroup” variable should be set to a group that contains all of the people using Horta to trace neurons. If a neuron is owned by this group, any member of the group can take ownership immediately. This group is expected to be used for ownership of samples and workspaces as well, so it may contain people who are not tracers but who will be looking at the same data and/or the tracers’ work. The “activetracersgroup” variable should be set to a group containing only people who are tracing. The members of this group will be listed in some neuron ownership change dialogs for convenience. If either group does not exist in the workstation database, the corresponding features will be disabled. Note: This scheme assumes that all tracers are members of one group that shares data freely. If you need to support multiple groups that will not be sharing data, you should currently deploy separate infrastructure (servers, etc) to support each group. ","categories":"","description":"Horta reference\n","excerpt":"Horta reference\n","ref":"/docs/user_manual/reference/","tags":"","title":"Reference"},{"body":"Currently ELK is only available in a swarm deployment because of how the ELK stack is configured.\nMost of the set up necessary for ELK - configuration files and/or data directories - is already done as part of filesystem initialization performed while executing:\n./manage.sh init-filesystems The current ELK data directories are created on /data/ directory so this directory must exist.\nOne manual step is to set the vm.max_map_count value required for running elasticsearch. This is done by adding vm.max_map_count=262144 line to /etc/sysctl.conf and then run sysctl -p (typically this must be done as root)\nAfter that deploying the elk stack for monitoring the application only requires starting with:\n./manage.sh start-elk The command to stop the monitoring is:\n./manage.sh stop-elk Import data from an old stack To import data from an old stack the old stack nodes must be whitelisted in the ELK_WHITELIST environment variable so that they can be accessible to the current cluster for importing indexes.\nSome useful elasticsearch endpoints:\nList available indices curl http://\u003cescoordinator\u003e:9200/_cat/indices Import an index from a remote cluster: #!/bin/bash remoteost=$1 indexName=$2 curl -H 'Content-Type: application/json' -X POST http://e03u08.int.janelia.org:9200/_reindex -d \"{ \\\"source\\\": { \\\"remote\\\": { \\\"host\\\": \\\"http://${remoteHost}:9200\\\" }, \\\"index\\\": \\\"${indexName}\\\", \\\"query\\\": { \\\"match_all\\\": {} } }, \\\"dest\\\": { \\\"index\\\": \\\"${indexName}\\\" } }\" Export kibana objects Here’s an example to export kibana visualizations but the command is identical for any one of [config, index-pattern, visualization, search, dashboard, url] - just set the appropriate type\ncurl http://\u003coldkibanahost\u003e:5601/api/saved_objects/_export -H 'kbn-xsrf: true' \\ -H 'Content-Type: application/json' \\ -d '{\"type\": \"visualization\" }' \u003e local/kibana-visualizations.ndjson To import Use the file generated by the above export command and run\ncurl -X POST http://e03u06.int.janelia.org:5601/api/saved_objects/_import \\ -H 'kbn-xsrf: true' \\ --form file=@local/kibana-visualizations.ndjson ","categories":"","description":"How to deploy ELK for log monitoring\n","excerpt":"How to deploy ELK for log monitoring\n","ref":"/docs/administration/bare_metal/elkdeployment/","tags":"","title":"Deploying ELK"},{"body":"A self-signed certificate is automatically generated during the init-filesystem step of a jacs-cm installation. For production use, it is recommended that you replace this certificate with a real one. The self-signed certificate is less secure, and it requires some extra steps to get working.\nIn order to connect to https://HOST1, you need to accept the certificate in the browser. This differs by browser.\nThen, in order to allow the Workstation to accept the certificate, it needs to be added to Java’s keystore. For this, you will need the certificate on the desktop computer where you are running the Workstation. You can either export it from the browser, or copy it over from the server. On the server, it is located in $CONFIG_DIR/certs/cert.crt. Once you have the certificate, you can import it using Java’s keytool.\nWindows On Windows, click Start and type “cmd” to find the Command Prompt, then right-click it and select “Run as administrator”. You need to find out where your JVM is installed by looking under C:\\Program Files\\Zulu. Then, import the certificate. Here it’s assumed the cert was saved to the current working directory:\nC:\\\u003e \"C:\\Program Files\\Zulu\\zulu-8\\bin\\keytool.exe\" -import -alias mouse1selfcert -file cert.crt -keystore \"C:\\Program Files\\Zulu\\zulu-8\\jre\\lib\\security\\cacerts\" -keypass changeit -storepass changeit The alias should be a descriptive name that will be used later if you want to remove or view the certificate. The password for the JVM keystore is actually “changeit”, so don’t change the keypass or storepass values above.\nMac or Linux First, you need to know where the JVM is located. You can use the same method that the Workstation uses to locate the JVM. This ensures you are modifying the correct one. Open a Terminal and type:\nexport JDK_HOME=`/usr/libexec/java_home -v 1.8` Now you can import the certificate into the keystore. Here it’s assumed the cert was saved to the desktop:\nsudo keytool -import -v -trustcacerts -alias mouse1 -file ~/Desktop/cert.crt -keystore $JDK_HOME/jre/lib/security/cacerts -keypass changeit -storepass changeit The alias should be a descriptive name that will be used later if you want to remove or view the certificate. The password for the JVM keystore is actually “changeit”, so don’t change the keypass or storepass values above.\n","categories":"","description":"Using self-signed server certificates\n","excerpt":"Using self-signed server certificates\n","ref":"/docs/administration/bare_metal/selfsignedcerts/","tags":"","title":"Self-signed Certificates"},{"body":"","categories":"","description":"How to contribute to the software\n","excerpt":"How to contribute to the software\n","ref":"/docs/development/contributing/","tags":"","title":"Contribution guidelines"},{"body":"We use Hugo to format and generate our website, the Docsy theme for styling and site structure, and GitHub Pages to manage the deployment of the site.\nHugo is an open-source static site generator that provides us with templates, content organization in a standard directory structure, and a website generation engine. You write the pages in Markdown (or HTML if you want), and Hugo wraps them up into a website.\nAll submissions, including submissions by project members, require review. We use GitHub pull requests for this purpose. Consult GitHub Help for more information on using pull requests.\nUpdating a single page If you’ve just spotted something you’d like to change while using the docs, Docsy has a shortcut for you:\nClick Edit this page in the top right hand corner of the page. If you don’t already have an up to date fork of the project repo, you are prompted to get one - click Fork this repository and propose changes or Update your Fork to get an up to date version of the project to edit. The appropriate page in your fork is displayed in edit mode. Previewing your changes locally If you want to run your own local Hugo server to preview your changes as you work:\nFollow the instructions to install Hugo. It must be the extended version, which supports SCSS.\nFork the HortaCloud website repo locally:\ngit clone --recurse-submodules --depth 1 https://github.com/JaneliaSciComp/hortacloud-website Run npm install and hugo server in the site root directory. By default your site will be available at http://localhost:1313/. Now that you’re serving your site locally, Hugo will watch for changes to the content and automatically refresh your site.\nContinue with the usual GitHub workflow to edit files, commit them, push the changes up to your fork, and create a pull request.\nCreating an issue If you’ve found a problem in the docs, but you’re not sure how to fix it yourself, please create an issue in the HortaCloud website repo. You can also create an issue about a specific page by clicking the Create Issue button in the top right hand corner of the page.\n","categories":"","description":"How to contribute to the docs\n","excerpt":"How to contribute to the docs\n","ref":"/docs/contribution-guidelines/","tags":"","title":"Editing the documentation"},{"body":"Importing imagery Single Sample Import If you already have the data on the S3 buckets in the Workstation, select File → New → Tiled Microscope Sample, and then set “Sample Name” to \u003csampleDirectoryName\u003e and “Path to Render Folder” as /\u003cbucketName\u003e/\u003csampleDirectoryName\u003e.\nOpen the Data Explorer (Window → Core → Data Explorer) and navigate to Home, then “3D RawTile Microscope Samples”, and your sample name. Right-click the sample and choose “Open in Horta”. This will open the Horta Panel and then from the Horta Panel you have options to create a workspace or to open the 2D or the 3D volume viewer.\nBatch Sample Import The workstation offers an option to import all your samples from an S3 Bucket mapped on the backend into the workstation. This can be done from the Workstation, select Services → Load Horta Data. This opens a dialog box that allows you to enter the location of your samples and the data owner. The location of your data can be entered like \u003cs3_bucket_name\u003e/\u003cfull_moouselight_data_prefix\u003e, e.g. janelia-mouselight-imagery/images. For sample owner typically select Mouselight Users (mouselight) from the drop down selection. Once you click OK the system will start a background task that will try to create new samples from all folders at the specified location and you will start seeing new samples under Home (mouselight)/3D Tile Microscope Samples as they are imported.\nSystem backup The system can be configured to run nightly backups. All it is needed is to specify a writeable bucket (HORTA_BACKUP_BUCKET) and a prefix (HORTA_BACKUP_FOLDER) that will hold the backups. Currently we only backup the Mongo database that contains samples info and tracing data and each backup will be stored in a timestamp (‘yyyyMMddHHmmss’) folder under the base backup prefix.\nSystem restore If system backups are available the sample and tracing data can be restored from a specified backup bucket (HORTA_RESTORE_BUCKET) and prefix (HORTA_RESTORE_FOLDER) which typically was created by the nightly backup job.\n","categories":"","description":"Day-to-day operation of the system\n","excerpt":"Day-to-day operation of the system\n","ref":"/docs/administration/aws/operation/","tags":"","title":"Operation"},{"body":"The Workstation/JACS system relies on JADE for its storage API.\nAdding a new Storage Volume Add bootstrap to the JADE configuration\nOn HOST1, edit /opt/jacs/config/jade/config.properties and add a block for your new volume, for example:\nStorageVolume.s3data.RootDir=/s3data StorageVolume.s3data.VirtualPath=/s3jade StorageVolume.s3data.Shared=true StorageVolume.s3data.Tags=aws,cloud StorageVolume.s3data.VolumePermissions=READ,WRITE,DELETE The properties configure the volume as follows:\nRootDir: defines the actual path to the data on disk VirtualPath: optionally defines a virtual path which is mapped to the actual path Shared: true if the volume should be accessible to all volumes Tags: tags used by applications to find appropriate volumes VolumePermissions: list of operations that JADE can execute (READ,WRITE,DELETE) Also add your volume to StorageAgent.BootstrappedVolumes, so that it will be created the next time the service is restarted.\nMount the path into the containers\nEdit the compose/swarm files for your deployment and mount the volume path as a Docker volume. For example, if your DEPLOYMENT is jacs, and STAGE is dev, you must edit these two files:\ndeployments/jacs/docker-compose.dev.yml deployments/jacs/docker-swarm.dev.yml\nYou should add your volume for all services jade-agent\u003cN\u003e which you want to service that volume.\nFor example:\njade-agent1: volumes: - /data/s3data:/s3data:shared Restart the stack after making the changes above and the volume will be created when the JADE worker starts.\nHost-specific Volumes By default, all JADE agents are configured to serve all volumes in the database. You can use StorageAgent.ServedVolumes to control which volumes are served by which hosts.\n","categories":"","description":"Managing storage volumes on JADE\n","excerpt":"Managing storage volumes on JADE\n","ref":"/docs/administration/bare_metal/storagevolumes/","tags":"","title":"Storage volumes"},{"body":"In principle, any 3d volumetric data can be imported into the MouseLight Workstation. At this moment we only provide some very basic tools for converting only TIFF format images into the expected format on disk. Another limitation of the current tools is that the entire volume must be in a single tiff file (per channel)\nThe imagery for MouseLight Workstation is a directory containing TIFF and KTX images organized into octrees. JACS compute includes a a service that can generate the octree data from a single volume TIFF file. If there is more than 1 channel, the channels are numbered 0 .. n-1 and each channel is expected to be in its own file. For example if you have 2 channels you would have two tiff files:\n/path/to/volume/volume.0.tiff /path/to/volume/volume.1.tiff The import service requires docker or singularity installed because the actual conversion services are packaged in two docker containers - one that generates a TIFF octree and the other one that takes the TIFF octree and converts the octant channel images into the correspomding ktx blocks.\nCurrently pre-built containers for tiff octree tool and ktx tool are only available at Janelia’s internal registry, but the containers build files are available at https://github.com/JaneliaSciComp/jacs-tools-docker.git in the ’tiff_octree’ and ‘ktx_octree’ subdirectories, respectively. KTX tool container can also be built from https://github.com/JaneliaSciComp/pyktx.git.\nGenerating the sample octree requires only a JACS Async service call which is a simple HTTP REST call that can be done using curl or Postman. This service can also be invoked from the JACS dashboard http://api-gateway-host:8080 by going to the “Services List” after Login and selecting “lvDataImport”. The dashboard should also offer a brief description of each argument.\ncurl invocation to run the service with singularity (this is the JACS default):\ncurl -X POST \\ https://api-gateway-host/SCSW/JACS2AsyncServices/v2/async-services/lvDataImport \\ -H 'Accept: application/json' \\ -H 'Content-Type: application/json' \\ -H 'Authorization: Bearer Your_Token' \\ -d '{ \"args\": [ \"-containerProcessor\", \"singularity\", \"-inputDir\", \"/path/to/volumeData\", \"-inputFilenamePattern\", \"test.{channel}.tif\", \"-outputDir\", \"/path/to/lvv/sampleData\", \"-channels\", \"0,1\", \"-levels\", \"4\", \"-voxelSize\", \"1,1,1\", \"-subtreeLengthForSubjobSplitting\", 2, \"-tiffOctreeContainerImage\", \"docker://registry.int.janelia.org/jacs-scripts/octree:1.0\", \"-ktxOctreeContainerImage\", \"docker://registry.int.janelia.org/jacs-scripts/pyktx:1.0\" ], \"resources\": { } } ' curl invocation to run the service with docker:\ncurl -X POST \\ https://api-gateway-host/SCSW/JACS2AsyncServices/v2/lvDataImport \\ -H 'Accept: application/json' \\ -H 'Content-Type: application/json' \\ -H 'Authorization: Bearer Your_Token' \\ -d '{ \"args\": [ \"-containerProcessor\", \"docker\", \"-inputDir\", \"/path/to/volumeData\", \"-inputFilenamePattern\", \"default.{channel}.tif\", \"-outputDir\", \"/path/to/lvv/sampleData\", \"-channels\", \"0\", \"-levels\", \"3\", \"-voxelSize\", \"1,1,1\", \"-subtreeLengthForSubjobSplitting\", 3, \"-tiffOctreeContainerImage\", \"registry.int.janelia.org/jacs-scripts/octree:1.0\", \"-ktxOctreeContainerImage\", \"registry.int.janelia.org/jacs-scripts/pyktx:1.0\" ], \"resources\": { } } ' Arguments description containerProcessor - which container runtime to use docker or singularity inputDir - path to original volume data inputFileNamePattern - original tiff name. Notice that if you have multiple channels and the channel is anywhere in the name you can use {channel} which will be replaced with the actual channel number. outputDir - where the octree will be generated - typically this is the sample data directory that will be imported in the workstation channels - specifies a list of all available channels, e.g. ‘0,1’ if there are two channels or ‘0’ if there is only 1 channel. levels - the number of octree levels. This is left up to the user and the service will not try to figure out the optimum value for the number of octree levels. voxelSize - specifies the voxel size in um. tiffOctreeContainerImage - tiff octree container image. Not that the format is slightly different for specifying the image name if docker is used or if singularity is used. Since singularity supports docker images, if singularity runtime is used you need to explictily specify that the image is a docker image. ktxOctreeContainerImage - ktx octree container image. See above regarding the format based on container processor type. subtreeLengthForSubjobSplitting - this parameter applies only for the ktx processor and it tells the service how to split the job and it has a default value of 5. The conversion process typically starts at a certain node and it performs tiff to ktx conversion for a specified number of levels. If you start a process at the root and convert all levels the job may take a while so if you want you have the option to parallelize it by going only for a limited number of levels from the root and start new jobs from all nodes at the level equal with the subtree depth. For example if you have 8 levels and you set subtreeLengthForSubjobSplitting to 3 then KTX conversion will start 1 + 8^3 + 8^6 = 1 + 512 + 262144 = 262657 jobs with the following parameters: \"\" 3, \"111\" 3, \"112\" 3, ..., \"118\" 3, ..., \"888\" 3, ..., \"111111\" 3, ..., \"888888\" 3 If you leave the default (subtreeLengthForSubjobSplitting=5) then the KTX conversion will start only 1 + 8^5 = 32769 jobs (\"11111\" 5, ..., \"88888\" 5) Note that the service invocation requires authentication so before you invoke it, you need to obtain an JWS token from the authentication service - see the Verify Functionality section on this page.\n","categories":"","description":"How to convert data into Horta format\n","excerpt":"How to convert data into Horta format\n","ref":"/docs/administration/bare_metal/dataimport/","tags":"","title":"Data import"},{"body":"Docker These are some useful commands for troubleshooting Docker:\nView logs for Docker daemon\nsudo journalctl -fu docker Restart the Docker daemon\nsudo systemctl restart docker Remove all Docker objects, including unused containers/networks/etc.\nsudo docker system prune -a Swarm GUI If you would like to see the Swarm’s status in a web-based GUI, we recommend installing Swarmpit. It’s a single command to deploy, and it works well with the JACS stack.\nCommon issues config variable not set If you see a lot of errors or warnings similar to the ones below, first check that the .env file was generated correctly - it should have all environment variables from .env.config, present and set. If it is not just remove it and try the commands again. It is possible that you may have run a command like ./manage.sh init-filesystems before the swarm cluster was available.\nWARN[0000] The \"CONFIG_DIR\" variable is not set. Defaulting to a blank string. WARN[0000] The \"DATA_DIR\" variable is not set. Defaulting to a blank string. WARN[0000] The \"DB_DIR\" variable is not set. Defaulting to a blank string. WARN[0000] The \"BACKUPS_DIR\" variable is not set. Defaulting to a blank string. WARN[0000] The \"CERT_SUBJ\" variable is not set. Defaulting to a blank string. WARN[0000] The \"DEPLOYMENT\" variable is not set. Defaulting to a blank string. WARN[0000] The \"MONGODB_SECRET_KEY\" variable is not set. Defaulting to a blank string. WARN[0000] The \"API_GATEWAY_EXPOSED_HOST\" variable is not set. Defaulting to a blank string. WARN[0000] The \"RABBITMQ_EXPOSED_HOST\" variable is not set. Defaulting to a blank string. WARN[0000] The \"RABBITMQ_USER\" variable is not set. Defaulting to a blank string. WARN[0000] The \"RABBITMQ_PASSWORD\" variable is not set. Defaulting to a blank string. WARN[0000] The \"MAIL_SERVER\" variable is not set. Defaulting to a blank string. WARN[0000] The \"NAMESPACE\" variable is not set. Defaulting to a blank string. WARN[0000] The \"REDUNDANT_STORAGE\" variable is not set. Defaulting to a blank string. WARN[0000] The \"REDUNDANT_STORAGE\" variable is not set. Defaulting to a blank string. WARN[0000] The \"NON_REDUNDANT_STORAGE\" variable is not set. Defaulting to a blank string. WARN[0000] The \"NON_REDUNDANT_STORAGE\" variable is not set. Defaulting to a blank string. “network not found” If you see an intermittent error like this, just retry the command again:\nfailed to create service jacs-cm_jacs-sync: Error response from daemon: network jacs-cm_jacs-net not found bind errors during init-filesystems If during init-filesystems you see an error that the config folder could not be bound on a particular node of the swarm cluster, make sure you did not forget to create the config and db directories on each node that is part of the swarm. The directories must exist in order for docker to be able to mount the corresponding volumes. After you created all folders if you already ran ./manage.sh init-filesystems and it failed before you run it again stop it using\n./manage.sh stop and then you can try to re-run it\nRESTful services You can access the RESTful services from the command line. Obtain a JWT token like this:\n./manage.sh login The default admin account is called “root” with password “root” for deployments with self-contained authentication.\nNow you can access any of the RESTful APIs on the gateway, for instance:\nexport TOKEN=\u003center token here\u003e curl -k --request GET --url https://${API_GATEWAY_EXPOSED_HOST}/SCSW/JACS2AsyncServices/v2/services/metadata --header \"Content-Type: application/json\" --header \"Authorization: Bearer $TOKEN\" ","categories":"","description":"Common issues and solutions\n","excerpt":"Common issues and solutions\n","ref":"/docs/administration/bare_metal/troubleshooting/","tags":"","title":"Troubleshooting"},{"body":" About HortaCloud Fun fact: the name \"Horta\" comes from the name of a tunneling silicon based lifeform from the Star Trek original series episode 25 \"The Devil in the Dark\". Neuron traces in 3D resemble the tunnels such a creature might make in the ground. It can also be conveniently backronymed as \"How Outstanding Researchers Trace Axons\". This software is based on the Janelia Workstation and was originally developed for and in collaboration with the MouseLight Team Project at Janelia Research Campus.\nOngoing development and maintenance is funded by Janelia’s Open Science Software Initiative.\nScientific Advisors Jayaram Chandrashekar Scientific Advisor\nTiago Ferreira Scientific Advisor\nWyatt Korff Scientific Advisor\nNelson Spruston Scientific Advisor\nSoftware Developers Jody Clements Software Engineer\nCristian Goina Software Engineer\nTakashi Kawase Software Engineer\nDonald Olbris Software Engineer\nKonrad Rokicki Software Engineering Manager\nDavid Schauder Software Engineer\nRob Svirskas Software Engineer\n","categories":"","description":"","excerpt":" About HortaCloud Fun fact: the name \"Horta\" comes from the name of a …","ref":"/about/","tags":"","title":"About HortaCloud"},{"body":"","categories":"","description":"","excerpt":"","ref":"/categories/","tags":"","title":"Categories"},{"body":" ","categories":"","description":"","excerpt":" ","ref":"/community/","tags":"","title":"Community"},{"body":" HORTACLOUD Collaborative neuron annotation in the cloud\nDocumentation Login to HortaCloud-Janelia Your browser does not support the video tag. HortaCloud software provides an efficient production environment for collaborative and accurate reconstruction of long range projection neurons in light microscopy data. This software, originally developed for Janelia’s MouseLight Team Project, has allowed annotators to efficiently reconstruct entire axonal arbors of individual neurons from whole-brain light microscopy data.\nAutomated deployment Using the AWS CDK, you or your system administrator can easily deploy the entire software stack to an AWS Account with a single installation script.\nBrowser-based access We use a virtual desktop environment (VDI) called AWS AppStream to run the 3D rendering in the cloud, so you users don’t need to install any software or have access to a powerful workstation.\nBig brains, big data Mouse brain data as large as 30 TB has been successfully traced by our annotators. You can run a distributed data import tool to bring your data to HortaCloud.\nThe Next-Generation Platform for Neuron Tracing HortaCloud combines state-of-the-art volumetric visualization, advanced features for 3D neuronal annotation, and real-time multi-user collaboration with a set of enterprise-grade backend microservices for moving and processing large amounts of data rapidly and securely. Users can load multi-terabyte image volumes with up to three signal channels, and visualize them in 3D with multiscale volume rendering. An optimized workflow allows annotators to efficiently trace long range projection neurons in light microscopy data, including easy merging/splitting of skeletal reconstructions. Collaboration features allow a team of annotators to work together to annotate different neurons in a single volume, or build consensus by annotating the same neurons. Horta also provides other useful features, including: Movie scripting and rendering Import/export in SWC format Text annotations Color adjustments Shared workspaces Software architecture This software is built on the Janelia Workstation platform, leveraging Java NetBeans to provide modularity and extensibility. The backend consists of Java-based microservices that scale to handle large volumes of data. Metadata is stored in MongoDB and real-time event handling is implemented using RabbitMQ. We deploy both the client and backend services to the AWS Cloud, leveraging AWS AppStream to process the 3D rendering and virtualize the desktop infrastructure. Image data is stored on AWS S3, and we provide many open data sets on AWS Open Data registry that are immediately accessible in the application. Open Science In support of Open Science, Janelia’s MouseLight project has shared all of their code and data with the scientific community. We have started the HortaCloud community as a way to share this software platform and allow others to leverage and extend it.\nContributions welcome As an open source community project, we greatly welcome contributions and Pull Requests. Let us know if you would like to collaborate!\nRead more …\nFollow us on Twitter! For announcement of latest features and other developments.\nRead more …\n","categories":"","description":"","excerpt":" HORTACLOUD Collaborative neuron annotation in the cloud\nDocumentation …","ref":"/","tags":"","title":"HortaCloud"},{"body":"","categories":"","description":"","excerpt":"","ref":"/search/","tags":"","title":"Search Results"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/","tags":"","title":"Tags"}]